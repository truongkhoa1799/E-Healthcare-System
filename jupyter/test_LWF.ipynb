{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST FACE RECOGNITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LWF_FOLDER_FACE = '/Users/khoa1799/GitHub/DATA/LWF/data'\n",
    "LWF_CUT_FOLDER_FACE = '/Users/khoa1799/GitHub/DATA/LWF/cut_data'\n",
    "\n",
    "LWF_PATH_USER_ID = '/Users/khoa1799/GitHub/E-Healthcare-System/jupyter/model/LWF_ID_Face'\n",
    "LWF_PATH_USER_IMG_ENCODED = '/Users/khoa1799/GitHub/E-Healthcare-System/jupyter/model/LWF_Encoded_Face'\n",
    "LWF_KNN_MODEL_PATH = \"/Users/khoa1799/GitHub/E-Healthcare-System/jupyter/model/LWF_knn_clf_model.clf\"\n",
    "LWF_SVM_MODEL_PATH = \"/Users/khoa1799/GitHub/E-Healthcare-System/jupyter/model/LWF_svm_clf_model.clf\"\n",
    "\n",
    "PREDICTOR_5_POINT_MODEL = '/Users/khoa1799/GitHub/E-Healthcare-System/jupyter/model/shape_predictor_5_face_landmarks.dat'\n",
    "RESNET_MODEL = '/Users/khoa1799/GitHub/E-Healthcare-System/jupyter/model/dlib_face_recognition_resnet_model_v1.dat'\n",
    "\n",
    "IMAGE_SIZE = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FACE ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "pose_predictor_5_point = dlib.shape_predictor(PREDICTOR_5_POINT_MODEL)\n",
    "face_encoder = dlib.face_recognition_model_v1(RESNET_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_encodings(face_image, known_face_locations):\n",
    "    raw_landmarks = _raw_face_landmarks(face_image, known_face_locations)\n",
    "    return [np.array(face_encoder.compute_face_descriptor(face_image, raw_landmark_set, 1)) for raw_landmark_set in raw_landmarks]\n",
    "\n",
    "def _css_to_rect(css):\n",
    "    return dlib.rectangle(css[3], css[0], css[1], css[2])\n",
    "\n",
    "def _raw_face_landmarks(face_image, face_locations):\n",
    "    if face_locations is None:\n",
    "        face_locations = _raw_face_locations(face_image)\n",
    "    else:\n",
    "        face_locations = [_css_to_rect(face_location) for face_location in face_locations]\n",
    "\n",
    "    pose_predictor = pose_predictor_5_point\n",
    "\n",
    "    return [pose_predictor(face_image, face_location) for face_location in face_locations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET THE BOUNDING BOX CONTAINNING FACE IN IMAGE BUT NOT ALIGNED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cut_Img(loaded_img):\n",
    "    ret_img = loaded_img.copy()\n",
    "    \n",
    "    max_fra = max( loaded_img.shape[0], loaded_img.shape[1] ) / 320\n",
    "    new_height = int( loaded_img.shape[0] / max_fra )\n",
    "    new_width = int( loaded_img.shape[1] / max_fra )\n",
    "\n",
    "    resized_img = cv2.resize(loaded_img, ( new_width, new_height ))\n",
    "    RGB_resized_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    face_locations = face_recognition.face_locations(RGB_resized_img)\n",
    "    for (top, right, bottom, left) in face_locations:\n",
    "        top *= max_fra\n",
    "        bottom *= max_fra\n",
    "        left *= max_fra\n",
    "        right *= max_fra\n",
    "\n",
    "        return len(face_locations), ret_img[int(top):int(bottom),int(left):int(right)]\n",
    "    return 0, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD AND SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveData(known_face_IDs, known_face_encodings, path_user_id, path_user_img_encoded):\n",
    "    with open(path_user_id, mode='wb') as fp_1:\n",
    "        pickle.dump(known_face_IDs, fp_1)\n",
    "\n",
    "    with open(path_user_img_encoded, 'wb') as fp_2:\n",
    "        pickle.dump(known_face_encodings, fp_2)\n",
    "\n",
    "def SaveKNNModel(knn_clf, path_model):\n",
    "    if path_model is not None:\n",
    "        with open(path_model, 'wb') as f:\n",
    "            pickle.dump(knn_clf, f)\n",
    "\n",
    "def SaveSVMModel(svm_clf, path_model):\n",
    "    if path_model is not None:\n",
    "        with open(path_model, 'wb') as f:\n",
    "            pickle.dump(svm_clf, f)\n",
    "\n",
    "def LoadData(path_user_id, path_user_img_encoded):\n",
    "    known_face_IDs = None\n",
    "    known_face_encodings = None\n",
    "    if not os.path.exists(path_user_id):\n",
    "        print(\"There is no user id face to load\")\n",
    "        exit(-1)\n",
    "\n",
    "    with open (path_user_id, 'rb') as fp_1:\n",
    "        known_face_IDs = pickle.load(fp_1)\n",
    "\n",
    "    if not os.path.exists(path_user_img_encoded):\n",
    "        print(\"There is no user encoding face to load\")\n",
    "        exit(-1)\n",
    "\n",
    "    with open (path_user_img_encoded, 'rb') as fp_2:\n",
    "        known_face_encodings = pickle.load(fp_2)\n",
    "    \n",
    "    return known_face_IDs, known_face_encodings\n",
    "        \n",
    "def LoadKNNModel(path_model):\n",
    "    if not os.path.exists(path_model):\n",
    "        print(\"There is KNN model to load\")\n",
    "        exit(-1)\n",
    "\n",
    "    with open(path_model, 'rb') as f:\n",
    "        knn_clf = pickle.load(f)\n",
    "        return knn_clf\n",
    "\n",
    "def LoadSVMModel(path_model):\n",
    "    if not os.path.exists(path_model):\n",
    "        print(\"There is KNN model to load\")\n",
    "        exit(-1)\n",
    "\n",
    "    with open(path_model, 'rb') as f:\n",
    "        svm_clf = pickle.load(f)\n",
    "        return svm_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LWF DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "BASE_BRIGHTNESS = 180\n",
    "IMAGE_SIZE = 150\n",
    "\n",
    "def adjust_brightness(img):\n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV) #convert it to hsv\n",
    "    v = hsv_img[:, :, 2]\n",
    "    mean_v = np.mean(v)\n",
    "    diff = BASE_BRIGHTNESS - mean_v\n",
    "                   \n",
    "    if diff < 0:\n",
    "        v = np.where(v < abs(diff), v, v + diff)\n",
    "    else:\n",
    "        v = np.where( v + diff > 255, v, v + diff)\n",
    "\n",
    "    hsv_img[:, :, 2] = v\n",
    "    ret_img = cv2.cvtColor(hsv_img, cv2.COLOR_HSV2BGR)\n",
    "    # return BRG image\n",
    "    return ret_img\n",
    "\n",
    "def preprocessing(img):\n",
    "    # Resize image\n",
    "    resized_img = cv2.resize(img, (IMAGE_SIZE,IMAGE_SIZE))\n",
    "\n",
    "    # Adjust bright image\n",
    "    adjusted_brightness_img = adjust_brightness(resized_img)\n",
    "\n",
    "    # Change to RGB image\n",
    "    GRAY_resized_img = cv2.cvtColor(adjusted_brightness_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # return RGB image\n",
    "    return GRAY_resized_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST LWF DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfw_people = fetch_lfw_people(min_faces_per_person=1, resize=1.5, color=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create test, train, and unknown dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum images in one class: 1\n",
      "Maximum images in one class: 530\n",
      "\n",
      "Total images: 13233\n",
      "Total images for train: 1555\n",
      "Total images for test: 3870\n",
      "Total images unknown: 7808\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List BGR image\n",
    "X = lfw_people.images\n",
    "X = [cv2.normalize(src=x, dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)for x in X]\n",
    "X = [cv2.cvtColor(x, cv2.COLOR_RGB2BGR) for x in X]\n",
    "\n",
    "Y = lfw_people.target\n",
    "Y = [y for y in Y]\n",
    "\n",
    "freq = {}\n",
    "min = 10000\n",
    "max = 0\n",
    "\n",
    "for i in Y:\n",
    "    if (i in freq): \n",
    "        freq[i] += 1\n",
    "    else: \n",
    "        freq[i] = 1\n",
    "    \n",
    "    if freq[i] > max:\n",
    "        max = freq[i]\n",
    "    if freq[i] < min:\n",
    "        min = freq[i]\n",
    "        \n",
    "print(\"Minimum images in one class: {}\".format(min))\n",
    "print(\"Maximum images in one class: {}\".format(max))\n",
    "print()\n",
    "\n",
    "dict_Y_greater_5 = {}\n",
    "list_Y_greater_5 = []\n",
    "list_Y_unknown = []\n",
    "\n",
    "for i in freq:\n",
    "    if freq[i] <=5:\n",
    "        list_Y_unknown.append(i)\n",
    "    elif freq[i] > 5:\n",
    "        dict_Y_greater_5[i] = 0\n",
    "        list_Y_greater_5.append(i)\n",
    "\n",
    "# Create unknown people data\n",
    "X_unknown = []\n",
    "Y_unknown = []\n",
    "X_train = []\n",
    "Y_train = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "for i in range(len(Y)):\n",
    "    if Y[i] in list_Y_unknown:\n",
    "        X_unknown.append(X[i])\n",
    "        Y_unknown.append(Y[i])\n",
    "    else:\n",
    "        dict_Y_greater_5[Y[i]] += 1\n",
    "        if dict_Y_greater_5[Y[i]] <=5:\n",
    "            X_train.append(X[i])\n",
    "            Y_train.append(Y[i])\n",
    "        else:\n",
    "            X_test.append(X[i])\n",
    "            Y_test.append(Y[i])\n",
    "\n",
    "print(\"Total images: {}\".format(len(Y)))\n",
    "print(\"Total images for train: {}\".format(len(Y_train)))\n",
    "print(\"Total images for test: {}\".format(len(Y_test)))\n",
    "print(\"Total images unknown: {}\".format(len(Y_unknown)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of each images: (187, 141, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of each images: {}\".format(X[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE EMBEDDED CODE AND USER ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int=0, padding: float=0.25) -> _dlib_pybind11.vector\n    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),uint8], num_jitters: int=0) -> _dlib_pybind11.vector\n    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int=0, padding: float=0.25) -> _dlib_pybind11.vectors\n    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: List[numpy.ndarray[(rows,cols,3),uint8]], batch_faces: List[_dlib_pybind11.full_object_detections], num_jitters: int=0, padding: float=0.25) -> _dlib_pybind11.vectorss\n    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: List[numpy.ndarray[(rows,cols,3),uint8]], num_jitters: int=0) -> _dlib_pybind11.vectors\n\nInvoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x131f343f0>, array([[172, 176, 180, ...,  31,  30,  29],\n       [173, 177, 181, ...,  29,  27,  25],\n       [172, 177, 181, ...,  27,  25,  23],\n       ...,\n       [142, 144, 144, ..., 147, 147, 147],\n       [144, 145, 145, ..., 146, 146, 144],\n       [147, 147, 146, ..., 148, 147, 146]], dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x132143af0>, 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e2cab8efd26c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpreprocessed_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0membedded_face\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_encodings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mknown_face_encodings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_face\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-6369971714dc>\u001b[0m in \u001b[0;36mface_encodings\u001b[0;34m(face_image, known_face_locations)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mface_encodings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknown_face_locations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mraw_landmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_raw_face_landmarks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknown_face_locations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_face_descriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_landmark_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mraw_landmark_set\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_landmarks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_css_to_rect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-6369971714dc>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mface_encodings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknown_face_locations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mraw_landmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_raw_face_landmarks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknown_face_locations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_face_descriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_landmark_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mraw_landmark_set\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_landmarks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_css_to_rect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int=0, padding: float=0.25) -> _dlib_pybind11.vector\n    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),uint8], num_jitters: int=0) -> _dlib_pybind11.vector\n    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int=0, padding: float=0.25) -> _dlib_pybind11.vectors\n    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: List[numpy.ndarray[(rows,cols,3),uint8]], batch_faces: List[_dlib_pybind11.full_object_detections], num_jitters: int=0, padding: float=0.25) -> _dlib_pybind11.vectorss\n    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: List[numpy.ndarray[(rows,cols,3),uint8]], num_jitters: int=0) -> _dlib_pybind11.vectors\n\nInvoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x131f343f0>, array([[172, 176, 180, ...,  31,  30,  29],\n       [173, 177, 181, ...,  29,  27,  25],\n       [172, 177, 181, ...,  27,  25,  23],\n       ...,\n       [142, 144, 144, ..., 147, 147, 147],\n       [144, 145, 145, ..., 146, 146, 144],\n       [147, 147, 146, ..., 148, 147, 146]], dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x132143af0>, 1"
     ]
    }
   ],
   "source": [
    "known_face_IDs = []\n",
    "known_face_encodings = []\n",
    "IMAGE_SIZE = 150\n",
    "\n",
    "time_start = time.time()\n",
    "for i in range(len(X_train)):\n",
    "    img = X_train[i]\n",
    "    user_ID = Y_train[i]\n",
    "    \n",
    "    preprocessed_img = preprocessing(img)\n",
    "\n",
    "    embedded_face = face_encodings(preprocessed_img, [(0,IMAGE_SIZE,IMAGE_SIZE,0)])[0]\n",
    "\n",
    "    known_face_encodings.append(embedded_face)\n",
    "    known_face_IDs.append(user_ID)\n",
    "\n",
    "SaveData(known_face_IDs, known_face_encodings, LWF_PATH_USER_ID, LWF_PATH_USER_IMG_ENCODED)\n",
    "print(\"Time load data {}\".format(time.time() - time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN KNN FOR LWF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing train KNN Model: 0.00308990478515625 second\n"
     ]
    }
   ],
   "source": [
    "# KNN PARAs\n",
    "NUM_NEIGHBROS = 5\n",
    "KNN_ALGORITHM = 'auto'\n",
    "KNN_WEIGHTS = 'uniform'\n",
    "\n",
    "knn_clf = None\n",
    "known_face_IDs = []\n",
    "known_face_encodings = []\n",
    "\n",
    "# Load data\n",
    "known_face_IDs, known_face_encodings = LoadData(LWF_PATH_USER_ID, LWF_PATH_USER_IMG_ENCODED)\n",
    "\n",
    "# Create and train the KNN classifier\n",
    "time_request = time.time()\n",
    "knn_clf = neighbors.KNeighborsClassifier(n_neighbors=NUM_NEIGHBROS, algorithm=KNN_ALGORITHM, weights=KNN_WEIGHTS, metric='euclidean')\n",
    "\n",
    "# self.__known_face_encodings is list of ndarray\n",
    "# self.__known_face_IDs is list of str\n",
    "knn_clf.fit(known_face_encodings, known_face_IDs)\n",
    "SaveKNNModel(knn_clf, LWF_KNN_MODEL_PATH)\n",
    "print(\"Finishing train KNN Model: {} second\".format(time.time() - time_request))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure distance parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean correct distance: 0.3913046669594229\n",
      "Max correct distance: 0.5488320656333571\n",
      "Min correct distance: 0.18617529925446935\n",
      "Variance correct distance: 0.002898015503305196\n",
      "\n",
      "Mean incorrect distance: 0.5011503510295898\n",
      "Max incorrect distance: 0.5560722799212208\n",
      "Min incorrect distance: 0.4444566442822639\n",
      "Variance incorrect distance: 0.0010349061167313678\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA3WElEQVR4nO3dd1hUZ9rH8e9Dr6I0RQHBigrYEFtce2KMMZqySUzvdZNsym6ab3Y3dTfZJJpk043piSZR00y1x4odG3ZAUVCkiSDlef84YNCIDkw5U+7PdXHNMMyc8+MAN2ee8xSltUYIIYTr8TI7gBBCiOaRAi6EEC5KCrgQQrgoKeBCCOGipIALIYSL8nHkziIjI3VCQoIjdymEEC5v9erVh7TWUac+7tACnpCQQEZGhiN3KYQQLk8ptfd0j0sTihBCuCgp4EII4aKkgAshhItyaBv46VRVVZGbm0tFRYXZUVxOQEAAsbGx+Pr6mh1FCGEC0wt4bm4uoaGhJCQkoJQyO47L0Fpz+PBhcnNzSUxMNDuOEMIEpjehVFRUEBERIcW7iZRSREREyDsXITyY6QUckOLdTHLchPBspjehCCGc2PFy2DgTinPBxx+SL4bwDmanEnWkgJukqKiITz75hDvvvNPsKEKc3oYZMPdvcOzI74/Newp6XQUX/Bd8A8zLJgAnaUJxRdXV1Wf8/GyKior43//+Z8tIQtjOb1Phq1sgsivc8AM8UQT3b4WBd8G6j+CjS6Ci2OyUHk/OwIEPPviAF154AaUUqampPPnkk9x4440cOnSIqKgo3nvvPeLj47n++usJCAhg7dq1DB48mMLCwpM+v+uuu7jrrrsoKCggKCiIt99+m6SkJA4ePMjtt9/Orl27AHj99deZOnUqO3fupFevXowePZrnn3/e5KMgRJ0NM+HnydBjIkx802g6AWgRA+c9DTG9YPbt8OUtcOVn4CXngWY5awFXSk0DxgH5WuvkuseeBy4EjgM7gRu01kXWhvnnN5vYvL/E2s2cpHvbFjxxYY9Gv75p0yaeeuopli5dSmRkJIWFhVx33XUnPqZNm8Y999zD7NmzAaPb49KlS/H29ub6668/6fORI0fyxhtv0LlzZ1asWMGdd97JvHnzuOeeexg6dCizZs2ipqaGsrIynnvuOTIzM1m3bp1Nv18hrHJoB3x7H8QNgIvfAe/TlIjUy4xmlbkPwbJXYfA9Do8pDJb865wOjDnlsZ+BZK11KpAFPGLjXA4zb948LrvsMiIjIwEIDw9n2bJlTJo0CYBrrrmGJUuWnHj+ZZddhre39x8+LysrY+nSpVx22WX06tWL2267jby8vBP7uOOOOwDw9vYmLCzMUd+eEJbT2jiz9vaDS6edvnjXS78Fuo2HX/8JBdscl1Gc5Kxn4FrrRUqphFMe+6nBp8uBS20R5kxnys4iODj4tJ/X1tbSsmVLOaMWrmvjF5C7Cia8DmHtzvxcpWDcS7BrIfz0OFw10zEZxUls0Xh1IzDXBtsxxYgRI5g5cyaHDx8GoLCwkEGDBvHZZ58B8PHHHzNkyJCzbqdFixYkJiYyc6bxi6y1Zv369QCMHDmS119/HYCamhqKi4sJDQ2ltLTUHt+SEE13vBx+ecJo3069wrLXBEfC0Idg+0+w4xe7xhOnZ1UBV0o9BlQDH5/hObcqpTKUUhkFBQXW7M4uevTowWOPPcbQoUPp2bMn999/P6+88grvvfceqampfPjhh0yZMsWibX388ce8++679OzZkx49ejBnzhwApkyZwvz580lJSaFv375s3ryZiIgIBg8eTHJyMg899JA9v0Uhzi5jGpTsg/OeadpFyfTboFUi/PovowlGOJTSFhz0uiaUb+svYtY9dj1wGzBSa11uyc7S0tL0qQs6bNmyhW7dujUhsmhIjp+wWvVxmNrLGKBz/bdNf/3q9+Gbe+DaOdBhmK3TCUAptVprnXbq4806A1dKjQH+Boy3tHgLIZxU5pfG2ffg+5r3+tTLIaQ1/GbZO1VhO2ct4EqpT4FlQFelVK5S6ibgVSAU+FkptU4p9Yadcwoh7EFrWDoVontAp5HN24ZvAAy4A3bOg7wNts0nzuisBVxrfaXWOkZr7au1jtVav6u17qS1jtNa96r7uN0RYYUQNpa9HPI3GwXYmsnR+t4APgGwerrNoomzkyFUQniyNR+AX6gxSZU1AltC9wnGxFfHj9oimbCAFHAhPNWxItg0C1IuBb/gsz79rPpeB5UlsHmO9dsSFpECLoSnyvwCqo9Bn2tts734gRDR2eiVIhxCCjgwaNAgsyOc0csvv0x5uXT2ETa2YQZEd4e2vW2zPaWg1yTIWQ5H9thmm+KMpIADS5cutdu2rZ12FqSACzsoyoacFZB8iXUXL0+VfIlxm/mV7bYpGiUFHAgJCQFgwYIFDBs2jEsvvZSkpCSuuuoq6gc6rVq1ikGDBtGzZ0/S09MpLS2loqKCG264gZSUFHr37s38+fMBmD59OuPHj2fEiBGMHDnyD58fPXqUG2+8kfT0dHr37n1ixGZNTQ0PPvggycnJpKam8sorrzB16lT279/P8OHDGT58uDkHSLif+gJbX3BtpVV7iE03+pYLu3Ou+cDnPgwHNtp2m21S4PznLH762rVr2bRpE23btmXw4MH89ttvpKenc/nll/P555/Tr18/SkpKCAwMZMqUKSil2LhxI1u3buXcc88lKysLgDVr1rBhwwbCw8OZPn36SZ8/+uijjBgxgmnTplFUVER6ejqjRo3igw8+YM+ePaxbtw4fHx8KCwsJDw/nxRdfZP78+SdmTBTCaplfQru+EJ5o+20nXwI//B3yt0J0ku23L06QM/BTpKenExsbi5eXF7169WLPnj1s27aNmJgY+vXrBxgTV/n4+LBkyRKuvvpqAJKSkmjfvv2JAj569GjCw8NPbLfh5z/99BPPPfccvXr1YtiwYVRUVJCdnc0vv/zCbbfdho+P8X+14euFsJlDO+DABtuffdfrMRGUF2ySZhR7c64z8CacKduLv7//ifve3t7NarOGxqedBWOmwi+//JKuXbs2L6QQ1thaN99Jt/H22X5oa2NBiK3fwfBH7bMPAcgZuEW6du1KXl4eq1atAqC0tJTq6mqGDBnCxx8bEzFmZWWRnZ1tUVE+77zzeOWVV060r69duxYwztLffPPNE/80CgsLAWTqWWFb276HNqnQMs5++0gaCwczpTeKnUkBt4Cfnx+ff/45f/nLX+jZsyejR4+moqKCO++8k9raWlJSUrj88suZPn36SWfwjZk8eTJVVVWkpqbSo0cPJk+eDMDNN99MfHw8qamp9OzZk08++QSAW2+9lTFjxshFTGG9snzIWQlJF9h3P13HGrfbXHapAJdg0XSytiLTydqeHD/RJPVTv96+xLjAb0+vDTAWfWjOFLXiJDadTlYI4aK2zYWweGidfPbnWitpLOxdCuWF9t+Xh5ICLoSnqKqAXQug6xjbDt5pTJfzQdcY08wKu3CKAu7IZhx3IsdNNMne34y5TzqNdsz+2vWBwHBZL9OOTC/gAQEBHD58WIpRE2mtOXz4MAEBAWZHEa5ix6/g7Q8J5zhmf17e0HGEsd/aWsfs08OY3g88NjaW3NxcnHHBY2cXEBBAbGys2TGEq9jxMyQMBr8gx+2z0yhj1sMDG6BtL8ft10OYXsB9fX1JTLTDcF4hxO+O7IVDWcbKOY5Uv0zbjp+lgNuB6U0oQggHqG+H7uyg9u96IdEQ08toRhE2JwVcCE+wawGExUFEJ8fvu+MIyF0FlTKa2NakgAvh7mprYPci6DDUMd0HT9VhGNRWG33ChU1JARfC3eWth4oiSBxmzv7j+hsr1u9aYM7+3ZgUcCHcXX3h7DDUnP37BkD8ACngdiAFXAh3t2sBRPcwLiiapcMwyN8MpQfNy+CGzlrAlVLTlFL5SqnMBo+FK6V+Vkptr7ttZd+YQohmqaow1r406+y7Xodhxu3uRabGcDeWnIFPB8ac8tjDwK9a687Ar3WfCyGcTe4qqK6AxD+Zm6NNKgSEwR4p4LZ01gKutV4EnDqd2EXA+3X33wcm2DaWEMIm9iwxljeLH2huDi9vaD/YyCNsprlt4K211nl19w8ArRt7olLqVqVUhlIqQ4bLC+Fge5YYZ7+BLc1OYszBUrgLiveZncRtWH0RUxuzUDU6E5XW+i2tdZrWOi0qKsra3QkhLFVVYTShOGryqrOpz7H3N3NzuJHmFvCDSqkYgLrbfNtFEkLYRO5KqKmEhCFmJzG0TjbaweVCps00t4B/DVxXd/86YI5t4gghbKa+/bu9ye3f9U60gy82O4nbsKQb4afAMqCrUipXKXUT8BwwWim1HRhV97kQwpnsXWqsexkQZnaS3yWcY6xUX7Lf7CRu4azTyWqtr2zkSyNtnEUIYSvVlUb7d9qNZic5WX1vmL1LIeVSc7O4ARmJKYQ72r/O6P9tdvfBU7VJBb8QyF5mdhK3IAVcCHeUXTfzn7MVcG8fiO0He6WA24IUcCHc0d6lENkFQpyw6277wZC/CcpPHR8omkoKuBDuprYGslc439l3vfpeMTkrzM3hBqSAC+Fu8jdDZTG0H2R2ktNr1xe8/WSBBxuQAi6Eu8lebtw66xm4byC07f17TtFsUsCFcDfZyyE0BlrGm52kcXH9IW+dMdxfNJsUcCHcTc4Ko0Casf6lpeIHQM1x2L/W7CQuTQq4EO6keB8U5zhv80m9uP7GbY40o1hDCrgQ7qS+IMb3NzfH2QRHQkRno7eMaDYp4EK4k+zl4BsMrVPMTnJ28f2Nfzi1tWYncVlSwIVwJ9nLIbavMeLR2cUNgGNH4PB2s5O4LCngQriLyjI4mGkURlcQX5dTBvQ0mxRwIdzFvtWga3+/QOjsIjpBYCvIWWl2EpclBVwId1FfCGPTzM1hKaWMfzZSwJtNCrgQ7iJnBUR1c44FjC0Vlw6HtsnEVs0kBVwId1Bba6yBGZdudpKmqW/uyc0wN4eLkgIuhDs4lAUVxa7T/l2vbR9Q3nIhs5mkgAvhDuoLoKsVcL8giEmVAt5MUsCFcAe5K40eHREdzU7SdLHpsG8N1FSbncTlSAEXwh3krDIKoTNPYNWYuHSoOmrMYy6aRAq4EK7u2BGjJ0dsP7OTNE99t8dc6U7YVFLAhXB1uauN2zgXLeAt20NwtPEuQjSJVQVcKfVXpdQmpVSmUupTpVSArYIJISyUuxKUl7FUmStSymhGkTPwJmt2AVdKtQPuAdK01smAN3CFrYIJISyUsxKiu4N/qNlJmi+2HxTugqOHzE7iUqxtQvEBApVSPkAQsN/6SEIIi9XWGnOguGr7d736AUi50ozSFM0u4FrrfcALQDaQBxRrrX869XlKqVuVUhlKqYyCgoLmJxVC/NGhbVBZ4nojME/Vtjd4+ci8KE1kTRNKK+AiIBFoCwQrpa4+9Xla67e01mla67SoqKjmJxVC/NGJCaxcvID7BkKbFDkDbyJrmlBGAbu11gVa6yrgK2CQbWIJISySu8p1B/CcKrafDOhpImsKeDYwQCkVpJRSwEhgi21iCSEskrvKKHyuOIDnVLF1A3oKpIxYypo28BXAF8AaYGPdtt6yUS4hxNkcK4KCra5/AbNe/YAeaQe3mFW9ULTWT2itk7TWyVrra7TWlbYKJoQ4i311A3jcpYC3SoDgKJlatglkJKYQrio3A1CuO4DnVEoZ/4xkQI/FpIAL4apyV0JUEgS0MDuJ7cT2g8M7ZIUeC/mYHUAIS9XWavYVHWNHfhk5R8qpqdUABPv70DEqhE7RIYQF+pqc0kFqa40z8O7jzU5iW/XNQbkZ0OVcc7O4ACngwqlVVNWwMKuAHzMP8MuWg5RUnLmLWVKbUM7r0YbzU9qQ1MaNzkxPdXgHVBS5fv/vU7XrY8zrkrtKCrgFpIALp1RSUcWHy/YybcluDh89TligL6O7tyEtoRWdo0OIjwjCz9toASw+VsWO/DK2HihlYVYBU+dtZ8qv2+mfGM5dwzsxpHMkyh262TVUP+DFXS5g1vMLhtY9pB3cQlLAhVOprqll+tI9TPl1O6UV1QztEsVN5yQysGMEvt6nv2TTMsiP9hHBjOzWmruGd6KgtJI56/bxzuLdXDttJb3iWvLUhGSS24U5+Luxo9yV4B8GkV3MTmJ7semwYQbU1oCXt9lpnJoUcOE0NuYW88isDWTuK2F41ygeOLdrs4puVKg/Nw/pwDUD2zNrzT7++3MW419dwg2DE7l/dBeC/d3g1z43A2L7gpcb9kOI7QcZ7xoLNUd3MzuNU3OD32Th6rTWvLVoF//5cRsRwX7876o+nJ/cxupmD38fb65Ij+f8lBj+/cNW3l2ym3lb83n96j6u3T5eWWosP5Y0zuwk9lE/MVfOSingZ+GG/76FKympqOL2j1bz7NytnNejNT/fP5SxKTE2bbMOC/TlmYkpfHbrAMoqq5nw2m/MWptrs+073L41oGvdr/27XngHCAyXdnALSAEXptlXdIyJr/3GL1vyefyCbrw2qY9duwEO6BDBd/ecQ2psS/76+XqenbsFrbXd9mc39YUt1k0G8JzqxIAeGZF5NlLAhSm2HSjlkv8tJb+0ko9u6s/NQzo4pKdIdGgAn9zcn6v6x/Pmwl08OHMDVTW1dt+vTeWsgsiuxiyE7iqunzHPy7Eis5M4NSngwuHWZB/hsjeWUqs1M24byMCOEQ7dv4+3F09NSOavo7rw5ZpcbvtwNRVVNQ7N0GxaG10IXXUBY0vV92/fJ2fhZyIFXDjUhtwirnt3Ja2C/fjyjkF0izHnYqJSintHdeapCcnM25rPnR+v4Xi1C5yJF+6CY4XuN4DnVPUDemSl+jOSAi4cZkteCde8u5KwIF8+vWUAceFBZkfi6gHtTxTxez9bS7WzN6ecWIHHzc/A/UONhZrlQuYZSQEXDrH70FGufmcFgb7efHrLANq2DDQ70glXD2jP5HHdmZt5gIe+2EBtrRNf2MxdCf4tjEms3F1sP8hdbcz7Ik5LCriwu8NllVz/3ko08PEt/Z3izPtUN52TyAOjuzBr7T5e/DnL7DiNy1llTB/rjgN4ThWXDpXFxsLN4rQ84LdAmKmiqoZbPsggr7iCt69No2NUiNmRGnX3iE5c0S+OV+fv4LOV2WbH+aPKUsjf5Por0Fsqrr9xKyv0NEoKuLAbrTUPzFjPmuwiXr68F33bO3e3N6UUT05I5k9donhsdiaLtxeYHelk+1YbA3g8pYCHd4CgCCngZyAFXNjN/xbs5LuNeTx8fhJjU2LMjmMRX28vXpvUm05RIdz9yVqyD5ebHel3OaswVuBJMzuJYyhl9LaRC5mNkgIu7GLBtnxe+Gkb43u25bY/dTA7TpOEBvjy1rV90Vpz64cZlB8/8xzkDpOzwpgbJLCl2UkcJy7dmNRKVug5LSngwub2Hj7KPZ+uJalNC/59SapLzsXdPiKYqVf2ZtvBUh7+cqP5Q+5ra40zUXfvPniq+uaiXOkPfjpSwIVNVVTVcMdHa1BK8dY1fQn0c935nId1jebBc7vy9fr9fLR8r7lhDmVBRfHvF/Y8Rds+oLyNdx/iD6SAC5t69vstbM4r4aXLezpld8GmumNoR0YkRfPkt1vYtL/YvCD17cCeVsD9giAmVS5kNsKqAq6UaqmU+kIptVUptUUpNdBWwYTr+SEzj/eX7eWWIYmMSGptdhyb8PJSvHBZT8KD/bj7k7WUVZrUHp69wphiNaKjOfs3U1x/owdOTZXZSZyOtWfgU4AftNZJQE9gi/WRhCvKKSznoS820DOuJQ+d516jBMOD/Zh6ZW/2Hj7K47M2mhMiZ7lRyFzweoLV4tKhqhwOmHTsnVizC7hSKgz4E/AugNb6uNa6yEa5hAupqdXcP2MdaHj1yt74+bhfy1x6Yjh/HdWF2ev2M2fdPsfu/OghYxX6eA9rPqkXN8C4lXbwP7DmLy0RKADeU0qtVUq9o5QKPvVJSqlblVIZSqmMggInGxghbOKNhTtZtecI/7yoh1u0ezfmjmEd6du+FY/PzmRf0THH7bi+cNUXMk8T1g7C4iB7udlJnI41BdwH6AO8rrXuDRwFHj71SVrrt7TWaVrrtKioKCt2J5xR5r5iXvo5iwtSY5jYu53ZcezKx9uLl/7ci9pazf2fr6PGUZNe5awAbz9o29sx+3NGcf2N42B2d04nY00BzwVytdb172u+wCjowkNUVNVw72driQzx5+kJyS7Z37up4iOCeGJ8D1bsLuSdxbscs9PsFRDTC3wDHLM/ZxQ/AErzoDjH7CROpdkFXGt9AMhRSnWte2gksNkmqYRL+O9P29hZcJTnL0ulZZCf2XEc5rK+sZzbvTX//TmL7QdL7buz6krYv9Zz5j9pTP33ny3t4A1Ze7XpL8DHSqkNQC/gGasTCZeQsaeQd5bsZlL/eIZ09qymMaUUT09MIdjPmwdnrrfvIhD710JNpXEG6slaJ4NfKGQvMzuJU7GqgGut19W1b6dqrSdorY/YKphwXseO1/DgzPW0DQvk0bHdzI5jiqhQf/51UTLrc4t5c5Edm1LqC1a8hw+x8PI21gGVC5kncb/+XsLunv9xG3sOl/P8pamE+PuYHcc041JjGJvShim/bCfLXk0pe5dBRGcIjrTP9l1J/EDI3wzH5DyxnhRw0SRrso/w3tLdXD0gnkGdPLuoKKV48qJkgv29+dsXG2zfK6W21hjA097Dz77rxQ8EtAyrb0AKuLBYZXUNf/9iAzEtAvj7GPcabdlcESH+/GN8D9blFDF96R7bbrxgizGBlac3n9Rr1xe8fGHvUrOTOA0p4MJir83fyfb8Mp6emEJogK/ZcZzG+J5tGZEUzQs/brPtAhDS/n0yvyBo20vawRuQAi4ssvVACf+bv4OJvdsxPCna7DhORSnFUxOS8fZSPDJrg+3mDt+7DELaQKsE22zPHcQPgP1roMqBI2GdmBRwcVY1tZqHv9xIWKAvk8d1NzuOU2rbMpCHz0/itx2H+XKNDeZK0dpoKmg/0DMnsGpM/CCoOQ771pidxClIARdn9dHyvazLKWLyuO6EB3vOgJ2mmpQeT1r7Vjz13WYOl1Vat7Eje6B0P7QfbJNsbqP9QEDB3t/MTuIUpICLM8orPsbzP25jSOdILurV1uw4Ts3LS/HMxSkcrazm6e+snFm5/kKdFPCTBbaC1j2kgNeRAi7O6Ik5m6iureXpCSkeMdeJtbq0DuWOoR35au0+FmVZMfvm3qXGAg5R0tvnD9oPNroSygIPUsBF437cdICfNh/kvlFdiI9w32libe3O4Z3oEBnM47Mzqaiqad5G9i6B9oPAS/5E/6D9IGOBh/3rzE5iOvntEKdVVlnNE3M2kdQmlJvOSTQ7jksJ8PXmqYnJZBeW88q87U3fQPE+ow1cmk9Or/64SDOKFHBxei/+lMXB0gqeuTgFX2/5NWmqQR0jubhPO95atKvpw+xPtH8Psn0wdxASBZFdpIAjBVycRua+YqYv3c2k9Hj6xLcyO47LemxsN4L9fXhs1kZqmzLMfs8iCAiDNin2C+fqEs4x+snXmLTItJOQAi5OUlOreXTWRsKD/fmbDJe3SkSIP4+e341Ve44wc3UTFiLYvdhoJvDytl84V5cwBI6XQt46s5OYSgq4OMlHy/eyIbeYyeO6ERYow+WtdWnfWNITwnl27lbL+oYX58KR3UaBEo2rPz67F5mbw2RSwMUJB0sqTvT5Ht9T+nzbgpeX4qmJyZRVVPPs3K1nf8HuxcZtohTwMwqJgqhusGex2UlMJQVcnPDkt5s5XlPLvy7yjPUtHaVL61Bu+VMHvlidy/Jdh8/85D2LjcEq0T0cE86VJQ4xJraqPm52EtNIARcALMwq4NsNedw1rBOJkcFmx3E794zoTGyrQB6fncnx6jMswXai/Vv+NM8q4Zy6/uCeOy+K/JYIKqpqmDw7kw6Rwdw+rIPZcdxSoJ83T16UzI78Mt5ubDX7wt1QnA2JQx0bzlUlDAGUR7eDSwEXvDZ/B9mF5Tw1IRl/H+n5YC/Dk6I5P7kNU3/dfvp5w3ctMG47DHNkLNcVFA4xqb8fNw8kBdzD7cgv442FO5nYu53HL5HmCP93YXd8vBST52T+cd7w3QshtC1EdjYnnCvqMMyYF+X4UbOTmEIKuAfTWvP47I0E+nrz2AWeubq8o8WEBfLAuV1ZmFXA3MwDv3+hthZ2LTQKklxAtlyHYVBbZQzq8UBSwD3YV2v2sXxXIX8/P4nIEH+z43iMawe2p0fbFvzj602UVNTNqHdwIxwrlOaTpoofCN7+sGu+2UlMYXUBV0p5K6XWKqW+tUUg4RhHjh7n6e+30Ce+JVf2izc7jkfx8fbimYkpFJRV8t8ftxkPnmj/lguYTeIbCPH9jXcvHsgWZ+D3AlbOXi8c7dm5Wyg5VsUzF6fg5SVv2R2tZ1xLrh3Qng+W72V9ThHsnGcMTAltY3Y019NhmPEOpizf7CQOZ1UBV0rFAhcA79gmjnCElbsLmZGRy01DEklq08LsOB7rgfO6EhXizz++XIXeuww6jTQ7kmvqWHfcds4zN4cJrD0Dfxn4G9DoyASl1K1KqQylVEZBgRUrlAibqKyu4dFZG2nXMpB7R0pvBzO1CPDliQt7EJa/ElVTCR1HmB3JNbVJhaBI2PGr2UkcrtkFXCk1DsjXWq8+0/O01m9prdO01mlRUVHN3Z2wkTcX7mJHfhlPTUgmyM/H7Dgeb2xKGyZFbKdC+5Ib1svsOK7Jy8v457dzntGbx4NYcwY+GBivlNoDfAaMUEp9ZJNUwi52FpTx6rwdjEuNYXhStNlxBKCUYrjPRlbRnf/7btcf+4YLy3QaCeWH4MAGs5M4VLMLuNb6Ea11rNY6AbgCmKe1vtpmyYRNaa159KuNBPh68X8Xdjc7jqhXlI3vkR34dhnFvK35fLcxz+xErqm++WnHL+bmcDDpB+4hZmTksGJ3IY+M7UZ0aIDZcUS97T8BkDbqzyS3a8E/vt5Mcbmstt5kIdEQ0xO2/2x2EoeySQHXWi/QWo+zxbaE7eWXVPD0d1tITwjn8rQ4s+OIhrJ+glYJ+ER35bmLUzlSfpxnvpdeuc3S+TzIXQnlhWYncRg5A/cAT3y9iYrqWp69RPp8O5Xj5cb8J53PA6VIbhfGzUMS+Twjh6U7DpmdzvV0OQ90rUf1RpEC7uZ+yDzA3MwD3DuyMx2jQsyOIxrasxiqK6DLuSceum9kF9pHBPHIrI0cO15jYjgX1LaP0Z0w6wezkziMFHA3Vnysiv+bk0m3mBbc+ieZ59vpZP0IvsHQ/pwTDwX6efPsxSnsPVzOy79kmRjOBXl5QedzjQuZHrJavRRwN/b0d5s5VFbJvy9JwddbftRORWujgHcYBr4nX1Qe1DGSK/rF8fbiXazLKTIlnsvqci5UFEHOCrOTOIT8VbuphVkFzMjI5bahHUmNbWl2HHGqvPVQkgtJY0/75Ucv6EbrFgE8NHM9ldXSlGKxjiPB2w+2fW92EoeQAu6GSiuqeOTLDXSKDpHh8s5q63egvKDLmNN+uUWAL89cnML2/DJe+XWHg8O5sIAWxpJ0W7813uW4OSngbuiZ77dyoKSC/1yaSoCvLJHmlLZ+Z8xlHdz4KkjDu0Zzad9YXl+4k425xQ4M5+KSLoAjeyDf/btjSgF3MwuzCvh0ZTY3D+lAn/hWZscRp1O4G/I3GYXmLCZf0J3IED8emLmOiippSrFI17GAMv5Jujkp4G6kuLyKv32xnk7RIdw/uovZcURj6gtL19O3fzcUFuTLc5ekknWwjJd+ll4pFgltDbH9YOs3ZiexOyngbuSJrzM5VHacF//cU5pOnNnm2cYUqOGJFj19eNdorkyP563Fu1i1x3NGGVql+3jjQnHhbrOT2JUUcDcxd2Mes9ft5+7hnaTXiTMrzoXcVdBjQpNe9tgF3YhtFcgDM9ZztNIz+jhbpftFxu3m2abGsDcp4G7gYEkFj8zaSHK7Ftw9opPZccSZbJ5j3Haf0KSXhfj78MKlPck5Us6T3262fS530zIe2vWFTbPNTmJXUsBdXG2t5sGZ66moquHly3vLgB1nt2k2tEmBiI5Nfmn/DhHcPrQjn63K4YfMA7bP5m66T4C8dW7djCJ/7S5u2m+7Wbz9EJPHdadTtMx14tSKcozZ8pp49t3QX0d1IbldCx7+agMHSypsl80d1TejbJplbg47kgLuwjbvL+E/P2xjVLfWTEqPNzuOOJuNM43blEubvQk/Hy+mXNGbiqoaHpixntpa9x+s0myt2kNcf9gww20H9UgBd1FHK6u5+9M1hAX58u9LUlBKpol1alobhSSuP7RKsGpTHaNC+L9xPViy4xBvLNppm3zuKuUyKNgCBzPNTmIXUsBd1OQ5mew+dJQpV/QiIsTf7DjibA5mGoUk9c822dyV6XFckBrDf3/KIkO6Fjaux8Xg5WP883RDUsBd0Berc/lqzT7uGdGZQR0bH4otnMiGz41C0n2iTTanlOLZi1No1zKQez5dS1H5cZts1+0ER0CnUbDxC6h1v5GsUsBdTNbBUibPzmRAh3DukYmqXENNFaz/3JirOjjCZpttEeDLq5N6U1BWKe3hZ9LzCijdD7sWmJ3E5qSAu5DSiipu/3A1wf4+TLmiN96yPJpr2PELHM2H3tfYfNOpsS15bGw3ft2az/8WyKyFp9V1LAS2grUfmZ3E5qSAuwitNQ/N3MDewnJendSb1i1kZXmXseZDCI6GzqPtsvnrBiVwUa+2/PfnLBZlFdhlHy7Nxx9SLzemmHWzBY+lgLuItxbt4odNB3h4TBIDOtjubbiws7J8Y43GnleAt69ddlHfHt4lOpR7P1tL7pFyu+zHpfW+GmqOu93FTCngLmDBtnz+/cNWxqa04eYhlk2AJJzE2g9B19il+aShID8f3rimL9U1mls/WE35cZkv5SRtUiCmF6ye7lZ9wptdwJVScUqp+UqpzUqpTUqpe20ZTBh2FpTxl0/X0rVNC164rKf093YltTWQ8R4k/gmi7D+9b2JkMFMn9WbrgRIenCkXNf+g381GV869S81OYjPWnIFXAw9orbsDA4C7lFLdbRNLgLGq/C3vZ+Dn7cXb1/YlyM/H7EiiKbJ+hOIco3A4yPCu0Txyfje+33iAqfO2O2y/LiH5EggIg1Vvm53EZppdwLXWeVrrNXX3S4EtQDtbBfN0x6trueOj1eQcKeeNa/oS2yrI7EiiqVa9DaFtoevZV96xpZuHJHJxn3a8/Mt25qzb59B9OzW/IOh1NWz5BkryzE5jEzZpA1dKJQC9gRWn+dqtSqkMpVRGQYFcIbeE1pqHv9zA0p2H+fclqfRLCDc7kmiq/C2wcx6k3Qjejn3nVH9Rs39iOA/N3MCKXYcdun+n1u8mo2lr1TtmJ7EJqwu4UioE+BK4T2tdcurXtdZvaa3TtNZpUVFR1u7OI7z0y3a+WruP+0d34eI+sWbHEc2x7FXwCTQKhgn8fbx565o04sIDueWDDHbkl5qSw+lEdDTWIl31Dhw/anYaq1lVwJVSvhjF+2Ot9Ve2ieTZPlq+l6m/bufPabH8RRZncE2lB43uar2vgiDz3j2FBfky/YZ0/Hy8uW7aKvKKj5mWxakMugcqimDtx2YnsZo1vVAU8C6wRWv9ou0iea456/YxeU4mI5OieXqizDDosla8bgyfH3Cn2UmICw9i+g39KDlWxdXvrOBwWaXZkcwX3x9i0413STVVZqexijVn4IOBa4ARSql1dR9nX2ZbnNb8rfk8MGM9/RLCee2qPrKyjqsqL4SVb0OPic1adccektuF8c51aeQeOcb1762itMK1i5ZNDLkfiva6/MAea3qhLNFaK611qta6V93H97YM5ykWZRVw+0erSYoJ5Z3r0mRFeVe2/H9wvAyG/s3sJCfp3yGC16/uw5a8Eq5/bxVlnr4wcpcx0CYVFr8ANa57LOQ0z2SLtxdwywcZJEYG88GN/WkRYJ/h1sIBygthxZvGUl7R3cxO8wcjkloz9crerMsp4rppKz27iCsFQ/8Ohbt+XynJBUkBN9GirAJuft8o3p/cMoDwYD+zIwlrLP5v3dn3w2YnadTYlBheqSvi109b6dnNKUkXGMPr5z8DVa65vqgUcJPM3ZgnxdudHNkLK9+CnpOgtXMPSG5YxCe97cEXNpWC0f+E4myX7RcuBdwEM1blcNcna0iJDePzWwdK8XYH854C5QXDHzE7iUXGpsTw1rV9yTpYymVvLmN/kYd2MewwDDqONNrCXXCqWSngDqS15tV52/nblxs4p3MUH96UTliQtHm7vL1LYeMMGHgXhLnOwKsRSa358Kb+FJRUcsnrS9mS94dxeJ7h3CehosT4J+xipIA7yPHqWh6cuYEXfspiYu92vHNtmkxO5Q5qquH7h6BFLAx5wOw0TZaeGM7ntw1Ea7jsjWUs2JZvdiTHa90D0m+BjGmwf53ZaZpECrgDHC6r5NppK/hyTS73jerMi3/uiZ+PHHq3sOJ1Y8X5Mc+AX7DZaZqle9sWzLprEPHhQdz0fgbTf9uNdqM5sy0y7BEIjoRv73OpboVSRexsQ24RF76yhDXZRbx0eU/uG9VFRli6i0M7jLfdXcdCt/Fmp7FKTFggM28fyPCuUfzjm808MGM9x4673yrujQpsCef/B/avhWWvmJ3GYlLA7URrzacrs7n0jWUopfjy9kFM7O067aPiLGqqYc5dxnqL414yejS4uGB/H966Jo37RnXmq7X7uOT1pew55PoTPlmsx0TodiHMf9aYTdIFSAG3g+JjVdz9yVoe+Woj6QnhfH33YFJiw8yOJWxp0X8gZzmc/zyEtjE7jc14eSnuG9WFd69LI/dIORdMXcxXa3LNjuUYSsEFL4J/KHxxI1Q5f88cKeA2tmznYcZOWcyPmw7wtzFdef/GdCJC/M2OJWxp9yJY+B/oeSX0vNzsNHYxsltr5t73J3q0DeP+Geu597O1FJUfNzuW/YVEw8Q3IX8zzP272WnOSgq4jZRVVvP47I1c+fZyfL0VX9wxiDuHdcLby/XfWosGjuyFmddDZGcY+4LZaeyqXctAPr11AH8d1YXvNuQx+qVF/LjpgNmx7K/zKDjnr7DmfWNNUycmBdxKWmt+yDzAeS8t4uMV2dx8TiJz7/0TveJamh1N2FpFCXx6JdRWw5WfgX+I2YnszttLce+ozsy+azBRIf7c9uFq7vx4tfsP/BkxGTqNhu8fhN2LzU7TKOXI7kJpaWk6IyPDYfuzt50FZfzzm80syiogqU0oT09MoW/7VmbHEvZQVQEfXwrZy+CqmdBxhNmJHK6qppY3F+7klXk78FKKv4zsxE3nJOLv46azZ1YUwzujoTQPrv8WYnqaFkUptVprnfaHx6WAN11+aQVTf93OpytzCPL15q+ju3DtwPb4yBze7qm6EmZcB1lz4eK3IfXPZicyVU5hOU9+u5mfNh+kXctAHji3Cxf1aueezYXFufDueVBTCdd9Y9osk1LAbeBQWSXvLN7N+0v3UFVTy6T+8fxlRGeiQuUipds6Xg6fXw07fzXavNNvMTuR01iy/RDP/bCFzH0lJLUJ5Z6RnRnTow1e7lbID22H6eOg5jhcO9uUM3Ep4FbIKSznvd/28MnKvVRW1zIutS0PjO5CQqRrjrwTFio9CJ9dCfvWwPhXoM81ZidyOrW1mm827GfKL9vZdegonaJDuGNoR8b1jHGvppXDO+GDi+DYEbj0PehyrkN3LwW8ibTWLNt1mPeX7uHnzQdRSjGhVzvuHN6RjlHuf/HK4+WshJk3wLFCuOQdY+5o0aiaWs33G/N4dd4Oth0sJTLEn6v6xzOpfzytWwSYHc82SvbDJ5cbUyeMmAyD7wMvxzSbSgG30P6iY8xau48ZGTnsPVxOyyBfJqXHc83A9sSEBZodT9hbTRX8NgUWPAst2sHlH5p68crVaK1ZvP0Q7/22m/nbCvBSMKxrNH9Oi2N4UpTrn5UfPwpz7oZNXxnT0I5/BcLa2X23UsDPIK/4GD9vPsg36/ezas8RAPonhnN5vzjOT44h0M/Ff+mEZXJWwncPwIENxrDqcS8bc2SIZtlz6CgzMnL4YnUu+aWVhAb4MKZHG8amxjCoY4TrFnOtjZkLf3oclDeMnAxpN4K3/aaGlgLeQFVNLetyilicVcCvW/PZtN+YB7lr61Au7BnDuNS20r7tSfK3wsLnYNMsCGkDY/9jrGspbKK6ppYlOw7xzfo8ftp0gNLKaoL8vBnSOZLhXaMZ3CmSuPAgs2M2XeFuY/bCXQsgsquxmEe3i+zSrOLRBfxoZTUbcotZvbeQVXuOkLGnkKPHa/BS0Ce+FaO6t2ZUt2g6RYc6PJswSW0t7F4IK9+Gbd+Db5CxIMPgez1igI5ZKqpqWLbrML9uOcivW/LJKzbWomwfEUR6Qjj9EsLp074VHSKDXaM3i9awbS788gQcyoKIztD/NqOraYDt5j/yiAKuteZASQVZB8vYdqCErXmlbNxXzI6CMuq/za6tQ+mX2IpzOkUxsEOErIjjSWprjB4lW7+BzK+gOAeCIiHtBuh/BwRHmJ3Qo2it2VlQxpLth/ht52Ey9hRypNxYZDnE34cebVvQo20YSTGhJLUJpWNUCMH+TroISm2N8Q5u2Wuwfw34BBjTDHcfD51GGRNkWcEuBVwpNQaYAngD72itnzvT860t4FprSo5Vk1dyjLyiCvYXHyOn8Bg5heXsLTzK7oKjHG0wh3HrFv4ktw0jJTaM1Ngw+sS3omWQrD/pcWqq4KtbjLe6x46Al4+xFmLPKyFpHPi6SS8JF2cU9KOsyT5C5r5iNuQWs/VACRVVtSee06ZFAImRwcSHBxEfEUS7loHEhAXQtmUg0S38naNdfd9qWPeJUdDLDxu/b7H9YPS/IC69WZu0eQFXSnkDWcBoIBdYBVyptd7c2GuaW8Cn/LKdmatzyC+t5Hh17Ulf8/VWxLYKIi48iI5RwXSICqFTVAjdYkKlWIvffXixMe1rxxHGGZFcnHQJNbWa7MJyth0oYWfBUXYWlLH70FFyCo9xqKzyD88PC/QlOtSf16/uS6dok5vCaqohZwXs+AV2zYfxr0Kb5GZtqrECbs37kXRgh9Z6V90OPgMuAhot4M3VuoU//RLCiQ71JyrUn9YtAmjbMoCYsEBatwhwzyG8wrau+crsBKIZvL0UiZHBJJ6mU0H58Wr2Fx1jf1EFecXHyC+pJL+0koLSSloEOEFTi7cPJAw2PnjCLruw5rtsB+Q0+DwX6H/qk5RStwK3AsTHxzdrR1ekx3NFevNeK4RwT0F+PnSKDvXozgd2H0aktX5La52mtU6Lioqy9+6EEMJjWFPA9wFxDT6PrXtMCCGEA1hTwFcBnZVSiUopP+AK4GvbxBJCCHE2zW4D11pXK6XuBn7E6EY4TWu9yWbJhBBCnJFVl2q11t8D39soixBCiCaQJWSEEMJFSQEXQggXJQVcCCFclEMns1JKFQB7HbbDP4oEDpm4f0u4QkZwjZyS0XZcIac7Z2yvtf7DQBqHFnCzKaUyTjefgDNxhYzgGjklo+24Qk5PzChNKEII4aKkgAshhIvytAL+ltkBLOAKGcE1ckpG23GFnB6X0aPawIUQwp142hm4EEK4DSngQgjhotyigCulxiiltimldiilHj7N1+9XSm1WSm1QSv2qlGrf4Gs1Sql1dR92nU3Rgpy3K6U21mVZopTq3uBrj9S9bptS6jxny6iUSlBKHWtwLN+wV0ZLcjZ43iVKKa2USmvwmFMcy8YyOvJYWvDzvl4pVdAgy80NvnadUmp73cd19spog5wO+Ru35OetlPpzXS3apJT6pMHjzTuWWmuX/sCYCXEn0AHwA9YD3U95znAgqO7+HcDnDb5W5kQ5WzS4Px74oe5+97rn+wOJddvxdrKMCUCmsxzLuueFAouA5UCasx3LM2R0yLG08Od9PfDqaV4bDuyqu21Vd7+Vs+Ws+5rd/8YtzNgZWFt/nIBoa4+lO5yBn1ibU2t9HKhfm/MErfV8rXV53afLMRafcDRLcpY0+DQYqL/CfBHwmda6Umu9G9hRtz1nyuhIZ81Z50ng30BFg8ec5lieIaOjWJrxdM4DftZaF2qtjwA/A2OcMKejWJLxFuC1uuOF1jq/7vFmH0t3KOCnW5uz3RmefxMwt8HnAUqpDKXUcqXUBDvkq2dRTqXUXUqpncB/gHua8lqTMwIkKqXWKqUWKqWG2CGfxTmVUn2AOK31d019rRNkBMccS0uPxSV1zY9fKKXqV+Fy1HFsyr5OlxMc8zduScYuQBel1G91WcY04bWn5Q4F3GJKqauBNOD5Bg+318bQ1knAy0qpjqaEq6O1fk1r3RH4O/C4mVka00jGPCBea90buB/4RCnVwox8Sikv4EXgATP2b4mzZHSaYwl8AyRorVMxzgzfNynH2Zwpp7P8jftgNKMMA64E3lZKtbRmg+5QwC1am1MpNQp4DBivta6sf1xrva/udhewAOhtZs4GPgMmNPO1zdXsjHVNEofr7q/GaA/sYoeMcPacoUAysEAptQcYAHxdd5HQWY5loxkdeCzPeiy01ocb/L28A/S19LVOktNRf+OWHI9c4GutdVVd810WRkFv/rG0d+O+Ay4e+GA0+ify+8WDHqc8pzfGH0HnUx5vBfjX3Y8EtnOaC00OzNm5wf0LgYy6+z04+cLbLuxz4c2ajFH1mTAu5OwDws06lqc8fwG/XyB0mmN5howOOZYW/rxjGtyfCCyvux8O7K77G2pVd9+0n/cZcjrkb9zCjGOA9xtkyQEirDmWNj/YZnwAYzH+m+0EHqt77F8YZ9sAvwAHgXV1H1/XPT4I2Fh3sDcCN5mccwqwqS7j/Ia/ABjvHnYC24DznS0jcEmDx9cAF5p5LE957gLqiqMzHcvGMjryWFrw8362Lsv6up93UoPX3ohxEXgHcIOZP+/Gcjryb9yCjAqj2WxzXZYrrD2WMpReCCFclDu0gQshhEeSAi6EEC5KCrgQQrgoKeBCCOGipIALIYSLkgIuhBAuSgq4EEK4qP8HpfA3f2EkYbEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "knn_clf = None\n",
    "known_face_IDs = None\n",
    "known_face_encodings = None\n",
    "\n",
    "dis_correct = []\n",
    "dis_incorrect = []\n",
    "\n",
    "total_faces = 0\n",
    "\n",
    "# Load KNN Model\n",
    "knn_clf = LoadKNNModel(LWF_KNN_MODEL_PATH)\n",
    "known_face_IDs, known_face_encodings = LoadData(LWF_PATH_USER_ID, LWF_PATH_USER_IMG_ENCODED)\n",
    "\n",
    "# print(len(known_face_IDs))\n",
    "for i in range(len(X_test)):\n",
    "    img = X_test[i]\n",
    "    \n",
    "    # Pre-processing\n",
    "    preprocessed_img = preprocessing(img)\n",
    "    \n",
    "    # Convert to embedded code\n",
    "    embedded_face = face_encodings(preprocessed_img, [(0,IMAGE_SIZE,IMAGE_SIZE,0)])[0]\n",
    "    embedded_face = embedded_face.reshape(1,-1)\n",
    "    \n",
    "    has_face = False\n",
    "    total_faces += 1\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Classifying\n",
    "    closet_distances = knn_clf.kneighbors(embedded_face, n_neighbors = 3)\n",
    "    face_id = knn_clf.predict(embedded_face)\n",
    "    \n",
    "    for j in range(len(closet_distances)):\n",
    "        if known_face_IDs[closet_distances[1][0][j]] == face_id[-1]:\n",
    "            if face_id[-1] == Y_test[i]:\n",
    "                dis_correct.append(closet_distances[0][0][j])\n",
    "            else:\n",
    "                dis_incorrect.append(closet_distances[0][0][j])\n",
    "    \n",
    "#     if total_faces > 3870:\n",
    "    if total_faces > 1000:\n",
    "        break\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "print(\"Mean correct distance: {}\".format(np.mean(dis_correct)))\n",
    "print(\"Max correct distance: {}\".format(np.max(dis_correct)))\n",
    "print(\"Min correct distance: {}\".format(np.min(dis_correct)))\n",
    "print(\"Variance correct distance: {}\".format(np.var(dis_correct)))\n",
    "print()\n",
    "\n",
    "print(\"Mean incorrect distance: {}\".format(np.mean(dis_incorrect)))\n",
    "print(\"Max incorrect distance: {}\".format(np.max(dis_incorrect)))\n",
    "print(\"Min incorrect distance: {}\".format(np.min(dis_incorrect)))\n",
    "print(\"Variance incorrect distance: {}\".format(np.var(dis_incorrect)))\n",
    "print()\n",
    "\n",
    "mu_correct = np.mean(dis_correct)\n",
    "variance_correct = np.var(dis_correct)\n",
    "sigma_correct = math.sqrt(variance_correct)\n",
    "x_correct = np.linspace(mu_correct - 3*sigma_correct, mu_correct + 3*sigma_correct, 100)\n",
    "y_correct = norm.pdf(x_correct, mu_correct, sigma_correct)\n",
    "\n",
    "mu_incorrect = np.mean(dis_incorrect)\n",
    "variance_incorrect = np.var(dis_incorrect)\n",
    "sigma_incorrect = math.sqrt(variance_incorrect)\n",
    "x_incorrect = np.linspace(mu_incorrect - 3*sigma_incorrect, mu_incorrect + 3*sigma_incorrect, 100)\n",
    "y_incorrect = norm.pdf(x_incorrect, mu_incorrect, sigma_incorrect)\n",
    "\n",
    "plt.plot(x_correct, y_correct, label='correct')\n",
    "plt.plot(x_incorrect, y_incorrect, label='incorrect')\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST FACE RECOGNITION FOR LWF DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khoa1799/.virtualenvs/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistic report for identifying known face:\n",
      "\tPrecision score: 0.9834455885826838\n",
      "\n",
      "\tTotal images: 3870\n",
      "\tTotal time: 6.885436773300171\n",
      "\tMaximum time processing time: 0.057720184326171875\n",
      "\tMinimum time processing time: 0.0013167858123779297\n",
      "\tMeans time: 0.001779182628759734\n",
      "\tStandard deviation time: 0.0018908394816202362\n",
      "\n",
      "Statistic report for identifying unknown face:\n",
      "\tPrecision score: 0.7094006147540983\n",
      "\n",
      "\tTotal images: 7808\n",
      "\tTotal time: 13.241910219192505\n",
      "\tMaximum time processing time: 0.02983403205871582\n",
      "\tMinimum time processing time: 0.0014190673828125\n",
      "\tMeans time: 0.0016959413702859253\n",
      "\tStandard deviation time: 0.001152126850693415\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "THRESHOLD_FACE_REC = 0.5\n",
    "knn_clf = None\n",
    "known_face_IDs = None\n",
    "known_face_encodings = None\n",
    "\n",
    "# known faces\n",
    "predict_known_face = []\n",
    "list_time_known_faces = []\n",
    "total_knonw_faces = 0\n",
    "\n",
    "# unknown faces\n",
    "predict_unknown_face = []\n",
    "list_time_unknown_faces = []\n",
    "total_unknown_faces = 0\n",
    "\n",
    "# Load KNN Model\n",
    "knn_clf = LoadKNNModel(LWF_KNN_MODEL_PATH)\n",
    "known_face_IDs, known_face_encodings = LoadData(LWF_PATH_USER_ID, LWF_PATH_USER_IMG_ENCODED)\n",
    "\n",
    "# KNOWN FACES\n",
    "for i in range(len(X_test)):\n",
    "    img = X_test[i]\n",
    "    \n",
    "    # Pre-processing\n",
    "    preprocessed_img = preprocessing(img)\n",
    "    \n",
    "    # Convert to embedded code\n",
    "    embedded_face = face_encodings(preprocessed_img, [(0,IMAGE_SIZE,IMAGE_SIZE,0)])[0]\n",
    "    embedded_face = embedded_face.reshape(1,-1)\n",
    "    \n",
    "    has_face = False\n",
    "    total_knonw_faces += 1\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Classifying\n",
    "    closet_distances = knn_clf.kneighbors(embedded_face, n_neighbors = 5)\n",
    "    face_id = knn_clf.predict(embedded_face)\n",
    "    meet_condition_threshold = [closet_distances[0][0][i] <= THRESHOLD_FACE_REC for i in range(len(closet_distances[0][0]))]\n",
    "    \n",
    "    for j in range(len(meet_condition_threshold)):\n",
    "        if meet_condition_threshold[j] and known_face_IDs[closet_distances[1][0][j]] == face_id[-1]:\n",
    "            predict_known_face.append(face_id[-1])\n",
    "            has_face = True\n",
    "            break\n",
    "    if has_face == False:\n",
    "        predict_known_face.append(-1)\n",
    "        \n",
    "    list_time_known_faces.append(time.time() - start_time)\n",
    "    # 3870\n",
    "    if total_knonw_faces > 3870:\n",
    "        break\n",
    "        \n",
    "# print(Y_test[0:total_knonw_faces])\n",
    "# print(predict_known_face)\n",
    "precision_score_known_faces = precision_score(Y_test[0:total_knonw_faces], predict_known_face, average='weighted')\n",
    "\n",
    "means = np.mean(list_time_known_faces)\n",
    "std = np.std(list_time_known_faces)\n",
    "total_time = np.sum(list_time_known_faces)\n",
    "\n",
    "print(\"Statistic report for identifying known face:\")\n",
    "\n",
    "print(\"\\tPrecision score: {}\".format(precision_score_known_faces))\n",
    "print()\n",
    "print(\"\\tTotal images: {}\".format(total_knonw_faces))\n",
    "print(\"\\tTotal time: {}\".format(total_time))\n",
    "print(\"\\tMaximum time processing time: {}\".format(numpy.max(list_time_known_faces)))\n",
    "print(\"\\tMinimum time processing time: {}\".format(numpy.min(list_time_known_faces)))\n",
    "print(\"\\tMeans time: {}\".format(means))\n",
    "print(\"\\tStandard deviation time: {}\".format(std))\n",
    "print()\n",
    "\n",
    "# UNKNOWN FACES\n",
    "unknown_faces = [-1]*len(X_unknown)\n",
    "for i in range(len(X_unknown)):\n",
    "    img = X_unknown[i]\n",
    "    \n",
    "    # Pre-processing\n",
    "    preprocessed_img = preprocessing(img)\n",
    "    \n",
    "    # Convert to embedded code\n",
    "    embedded_face = face_encodings(preprocessed_img, [(0,IMAGE_SIZE,IMAGE_SIZE,0)])[0]\n",
    "    embedded_face = embedded_face.reshape(1,-1)\n",
    "    \n",
    "    has_face = False\n",
    "    total_unknown_faces += 1\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Classifying\n",
    "    closet_distances = knn_clf.kneighbors(embedded_face, n_neighbors = 5)\n",
    "    face_id = knn_clf.predict(embedded_face)\n",
    "    meet_condition_threshold = [closet_distances[0][0][i] <= THRESHOLD_FACE_REC for i in range(len(closet_distances[0][0]))]\n",
    "    \n",
    "    for j in range(len(meet_condition_threshold)):\n",
    "        if meet_condition_threshold[j] and known_face_IDs[closet_distances[1][0][j]] == face_id[-1]:\n",
    "            predict_unknown_face.append(face_id[-1])\n",
    "            has_face = True\n",
    "            break\n",
    "    if has_face == False:\n",
    "        predict_unknown_face.append(-1)\n",
    "        \n",
    "    list_time_unknown_faces.append(time.time() - start_time)\n",
    "    \n",
    "#     Total face: 7808\n",
    "    if total_unknown_faces > 7808:\n",
    "        break\n",
    "        \n",
    "# print(unknown_faces[0:total_unknown_faces])\n",
    "# print(predict_unknown_face)\n",
    "precision_score_unknown_faces = accuracy_score(unknown_faces[0:total_unknown_faces], predict_unknown_face)\n",
    "\n",
    "means = np.mean(list_time_unknown_faces)\n",
    "std = np.std(list_time_unknown_faces)\n",
    "total_time = np.sum(list_time_unknown_faces)\n",
    "\n",
    "print(\"Statistic report for identifying unknown face:\")\n",
    "\n",
    "print(\"\\tPrecision score: {}\".format(precision_score_unknown_faces))\n",
    "print()\n",
    "print(\"\\tTotal images: {}\".format(total_unknown_faces))\n",
    "print(\"\\tTotal time: {}\".format(total_time))\n",
    "print(\"\\tMaximum time processing time: {}\".format(numpy.max(list_time_unknown_faces)))\n",
    "print(\"\\tMinimum time processing time: {}\".format(numpy.min(list_time_unknown_faces)))\n",
    "print(\"\\tMeans time: {}\".format(means))\n",
    "print(\"\\tStandard deviation time: {}\".format(std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN SVM FOR LWF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing train KNN Model: 0.6337647438049316 second\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA as RandomizedPCA\n",
    "\n",
    "svm_clf = None\n",
    "known_face_IDs = []\n",
    "known_face_encodings = []\n",
    "\n",
    "# Load data\n",
    "known_face_IDs, known_face_encodings = LoadData(LWF_PATH_USER_ID, LWF_PATH_USER_IMG_ENCODED)\n",
    "\n",
    "time_request = time.time()\n",
    "# print(\"Fitting the classifier to the training set\")\n",
    "# param_grid = {\n",
    "#          'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "#           'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],\n",
    "#           }\n",
    "# svm_clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid)\n",
    "# print(\"Best estimator found by grid search:\")\n",
    "# print(svm_clf.best_estimator_)\n",
    "\n",
    "# Found the best for C=5000.0 and gamma=0.0005:\n",
    "svm_clf = SVC(kernel='rbf', class_weight='balanced', C=5000.0, gamma=0.0005)\n",
    "svm_clf = svm_clf.fit(known_face_encodings, known_face_IDs)\n",
    "\n",
    "print(\"Finishing train KNN Model: {} second\".format(time.time() - time_request))\n",
    "SaveSVMModel(svm_clf, LWF_SVM_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistic report for identifying known face:\n",
      "\tAccurancy score: 0.9702970297029703\n",
      "\tPrecision score: 0.9933993399339935\n",
      "\tRecall score: 0.9702970297029703\n",
      "\tF1 score: 0.9804231203918541\n",
      "\n",
      "\tTotal images: 101\n",
      "\tTotal time: 0.14963722229003906\n",
      "\tMaximum time processing time: 0.005624055862426758\n",
      "\tMinimum time processing time: 0.001299142837524414\n",
      "\tMeans time: 0.0014815566563370205\n",
      "\tStandard deviation time: 7.371486516341538e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khoa1799/.virtualenvs/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "svm_clf = None\n",
    "known_face_IDs = None\n",
    "known_face_encodings = None\n",
    "\n",
    "predict_face = []\n",
    "list_time_processing = []\n",
    "\n",
    "total_faces = 0\n",
    "\n",
    "# Load SVM Model\n",
    "svm_clf = LoadSVMModel(LWF_SVM_MODEL_PATH)\n",
    "known_face_IDs, known_face_encodings = LoadData(LWF_PATH_USER_ID, LWF_PATH_USER_IMG_ENCODED)\n",
    "\n",
    "# print(len(known_face_IDs))\n",
    "for i in range(len(X_test)):\n",
    "    img = X_test[i]\n",
    "    \n",
    "    # Pre-processing\n",
    "    preprocessed_img = preprocessing(img)\n",
    "    \n",
    "    # Convert to embedded code\n",
    "    embedded_face = face_encodings(preprocessed_img, [(0,IMAGE_SIZE,IMAGE_SIZE,0)])[0]\n",
    "    embedded_face = embedded_face.reshape(1,-1)\n",
    "    \n",
    "    has_face = False\n",
    "    total_faces += 1\n",
    "    start_time = time.time()\n",
    "    \n",
    "    face_id = svm_clf.predict(embedded_face)\n",
    "    predict_face.append(face_id[-1])\n",
    "        \n",
    "    list_time_processing.append(time.time() - start_time)\n",
    "    \n",
    "#     Total: 3870\n",
    "    if total_faces > 100:\n",
    "        break\n",
    "\n",
    "accurancy_score = accuracy_score(Y_test[0:total_faces], predict_face)\n",
    "precision_score = precision_score(Y_test[0:total_faces], predict_face, average='weighted')\n",
    "recall_score = recall_score(Y_test[0:total_faces], predict_face, average='weighted')\n",
    "f1_score = f1_score(Y_test[0:total_faces], predict_face, average='weighted')\n",
    "\n",
    "means = np.mean(list_time_processing)\n",
    "std = np.std(list_time_processing)\n",
    "total_time = np.sum(list_time_processing)\n",
    "\n",
    "print(\"Statistic report for identifying known face:\")\n",
    "\n",
    "print(\"\\tAccurancy score: {}\".format(accurancy_score))\n",
    "print(\"\\tPrecision score: {}\".format(precision_score))\n",
    "print(\"\\tRecall score: {}\".format(recall_score))\n",
    "print(\"\\tF1 score: {}\".format(f1_score))\n",
    "print()\n",
    "print(\"\\tTotal images: {}\".format(total_faces))\n",
    "print(\"\\tTotal time: {}\".format(total_time))\n",
    "print(\"\\tMaximum time processing time: {}\".format(numpy.max(list_time_known_faces)))\n",
    "print(\"\\tMinimum time processing time: {}\".format(numpy.min(list_time_known_faces)))\n",
    "print(\"\\tMeans time: {}\".format(means))\n",
    "print(\"\\tStandard deviation time: {}\".format(std))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
