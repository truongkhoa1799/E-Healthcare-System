{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LWF DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn import neighbors\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_files_in_folder(folder):\n",
    "        return [os.path.join(folder, f) for f in os.listdir(folder) if re.match(r'.*\\.(jpg|jpeg|png)', f, flags=re.I)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET THE BOUNDING BOX CONTAINNING FACE IN IMAGE BUT NOT ALIGNED\n",
    "def Cut_Img(loaded_img):\n",
    "    ret_img = loaded_img.copy()\n",
    "    \n",
    "    max_fra = max( loaded_img.shape[0], loaded_img.shape[1] ) / 320\n",
    "    new_height = int( loaded_img.shape[0] / max_fra )\n",
    "    new_width = int( loaded_img.shape[1] / max_fra )\n",
    "\n",
    "    resized_img = cv2.resize(loaded_img, ( new_width, new_height ))\n",
    "    RGB_resized_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    face_locations = face_recognition.face_locations(RGB_resized_img)\n",
    "    for (top, right, bottom, left) in face_locations:\n",
    "        top *= max_fra\n",
    "        bottom *= max_fra\n",
    "        left *= max_fra\n",
    "        right *= max_fra\n",
    "\n",
    "        return len(face_locations), ret_img[int(top):int(bottom),int(left):int(right)]\n",
    "    return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance of 2 aligned image: 0.552473177612558\n",
      "Distance of 2 non aligned image: 0.41482112989099923\n",
      "Distance of 2 aligned image: 0.552473177612558\n",
      "Distance of 2 non aligned image: 0.41482112989099923\n",
      "Distance of 2 aligned image: 0.552473177612558\n",
      "Distance of 2 non aligned image: 0.41482112989099923\n",
      "Distance of 2 aligned image: 0.552473177612558\n",
      "Distance of 2 non aligned image: 0.41482112989099923\n"
     ]
    }
   ],
   "source": [
    "# TEST ALIGNED IMAGE AND NOT ALIGNED IMAGE\n",
    "%matplotlib inline\n",
    "#The line above is necesary to show Matplotlib's plots inside a Jupyter Notebook\n",
    "import face_recognition\n",
    "from matplotlib import pyplot as plt\n",
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "sp = dlib.shape_predictor(\"/Users/khoa1799/Documents/E-Healthcare-System/LWF/model/shape_predictor_5_face_landmarks.dat\")\n",
    "facerec = dlib.face_recognition_model_v1(\"/Users/khoa1799/Documents/E-Healthcare-System/LWF/model/dlib_face_recognition_resnet_model_v1.dat\")\n",
    "\n",
    "def findEuclideanDistance(source_representation, test_representation):\n",
    "    euclidean_distance = source_representation - test_representation\n",
    "    euclidean_distance = np.sum(np.multiply(euclidean_distance, euclidean_distance))\n",
    "    euclidean_distance = np.sqrt(euclidean_distance)\n",
    "    return euclidean_distance\n",
    "\n",
    "def Img_Aligned(loaded_img):\n",
    "    ret_img = loaded_img.copy()\n",
    "\n",
    "    resized_img = cv2.resize(loaded_img, ( 150, 150 ))\n",
    "    RGB_resized_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Convert a tuple in (top, right, bottom, left) order to a dlib `rect` object\n",
    "    img_shape = sp(RGB_resized_img, dlib.rectangle(0, RGB_resized_img.shape[1], RGB_resized_img.shape[0], 0))\n",
    "    img_aligned = dlib.get_face_chip(RGB_resized_img, img_shape)\n",
    "    img_representation = np.array(facerec.compute_face_descriptor(img_aligned))\n",
    "    return img_representation\n",
    "\n",
    "def Img_Not_Aligned(loaded_img):\n",
    "    resized_img = cv2.resize(loaded_img, (150, 150))\n",
    "    RGB_resized_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "    embedded_face = face_recognition.face_encodings(RGB_resized_img, [(0,150,150,0)])[0]\n",
    "    return embedded_face\n",
    "\n",
    "img1 = cv2.imread(\"/Users/khoa1799/Documents/E-Healthcare-System/LWF/cut_data/train/Abdullah_Gul/Abdullah_Gul_0001.jpg\")\n",
    "img2 = cv2.imread(\"/Users/khoa1799/Documents/E-Healthcare-System/LWF/cut_data/train/Abdullah_Gul/Abdullah_Gul_0002.jpg\")\n",
    "\n",
    "# Img_Aligned(img1)\n",
    "print(\"Distance of 2 aligned image: {}\".format(findEuclideanDistance(Img_Aligned(img1),Img_Aligned(img2))))\n",
    "print(\"Distance of 2 non aligned image: {}\".format(findEuclideanDistance(Img_Not_Aligned(img1),Img_Not_Aligned(img2))))\n",
    "\n",
    "img3 = cv2.imread(\"/Users/khoa1799/Documents/E-Healthcare-System/LWF/cut_data/train/Abdullah_Gul/Abdullah_Gul_0003.jpg\")\n",
    "img4 = cv2.imread(\"/Users/khoa1799/Documents/E-Healthcare-System/LWF/cut_data/train/Abdullah_Gul/Abdullah_Gul_0004.jpg\")\n",
    "\n",
    "# Img_Aligned(img1)\n",
    "print(\"Distance of 2 aligned image: {}\".format(findEuclideanDistance(Img_Aligned(img1),Img_Aligned(img2))))\n",
    "print(\"Distance of 2 non aligned image: {}\".format(findEuclideanDistance(Img_Not_Aligned(img1),Img_Not_Aligned(img2))))\n",
    "\n",
    "img5 = cv2.imread(\"/Users/khoa1799/Documents/E-Healthcare-System/LWF/cut_data/train/Abdullah_Gul/Abdullah_Gul_0005.jpg\")\n",
    "img6 = cv2.imread(\"/Users/khoa1799/Documents/E-Healthcare-System/LWF/cut_data/train/Abdullah_Gul/Abdullah_Gul_0011.jpg\")\n",
    "\n",
    "# Img_Aligned(img1)\n",
    "print(\"Distance of 2 aligned image: {}\".format(findEuclideanDistance(Img_Aligned(img1),Img_Aligned(img2))))\n",
    "print(\"Distance of 2 non aligned image: {}\".format(findEuclideanDistance(Img_Not_Aligned(img1),Img_Not_Aligned(img2))))\n",
    "\n",
    "img7 = cv2.imread(\"/Users/khoa1799/Documents/E-Healthcare-System/LWF/cut_data/train/Abdullah_Gul/Abdullah_Gul_0014.jpg\")\n",
    "img8 = cv2.imread(\"/Users/khoa1799/Documents/E-Healthcare-System/LWF/cut_data/train/Abdullah_Gul/Abdullah_Gul_0015.jpg\")\n",
    "\n",
    "# Img_Aligned(img1)\n",
    "print(\"Distance of 2 aligned image: {}\".format(findEuclideanDistance(Img_Aligned(img1),Img_Aligned(img2))))\n",
    "print(\"Distance of 2 non aligned image: {}\".format(findEuclideanDistance(Img_Not_Aligned(img1),Img_Not_Aligned(img2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DELETE LWF DATA FOLDERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(LWF_CUT_FOLDER_FACE + '/test_known')\n",
    "shutil.rmtree(LWF_CUT_FOLDER_FACE + '/test_unknown')\n",
    "shutil.rmtree(LWF_CUT_FOLDER_FACE + '/train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE LWF DATA FOLDERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test_unknown = os.path.join(LWF_CUT_FOLDER_FACE, 'test_unknown')\n",
    "os.mkdir(path_test_unknown)\n",
    "\n",
    "path_test_known = os.path.join(LWF_CUT_FOLDER_FACE, 'test_known') \n",
    "os.mkdir(path_test_known)\n",
    "\n",
    "path_train = os.path.join(LWF_CUT_FOLDER_FACE, 'train') \n",
    "os.mkdir(path_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE TRAIN AND TEST DATA FOR LWF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 5750\n"
     ]
    },
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/Users/khoa1799/Documents/E-Healthcare-System/LWF/cut_data/test_unknown/German_Khan'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-c837c55f0533>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCUT_FOLDER_FACE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test_unknown'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/Users/khoa1799/Documents/E-Healthcare-System/LWF/cut_data/test_unknown/German_Khan'"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "num_class_has_more_img = 0\n",
    "num_classes = 0\n",
    "user_ID = \"\"\n",
    "img_name = \"\"\n",
    "\n",
    "num_classes = len(os.listdir(os.path.join(LWF_FOLDER_FACE)))\n",
    "current_class = 1\n",
    "print(\"Number of classes: {}\".format(num_classes))\n",
    "\n",
    "# CREATE TRAIN AND TEST_unknown face DATA \n",
    "for class_dir in os.listdir(LWF_FOLDER_FACE):\n",
    "    if not os.path.isdir(os.path.join(LWF_FOLDER_FACE, class_dir)):\n",
    "        continue\n",
    "        \n",
    "    num_imgs = len(os.listdir(os.path.join(LWF_FOLDER_FACE, class_dir)))\n",
    "    \n",
    "    if num_imgs == 1:\n",
    "        for img in image_files_in_folder(os.path.join(LWF_FOLDER_FACE, class_dir)):\n",
    "            path = img.split('/')\n",
    "            img_name = path[-1]\n",
    "            loaded_img = cv2.imread(img)\n",
    "            \n",
    "            ret, img = Cut_Img(loaded_img)\n",
    "            path = None\n",
    "            if ret != 0:\n",
    "                if current_class > num_classes // 2:\n",
    "                    path = os.path.join(LWF_CUT_FOLDER_FACE, 'train', class_dir) \n",
    "                    os.mkdir(path)\n",
    "                else:\n",
    "                    path = os.path.join(LWF_CUT_FOLDER_FACE, 'test_unknown', class_dir) \n",
    "                    os.mkdir(path)\n",
    "                    \n",
    "                os.chdir(path)\n",
    "                cv2.imwrite(img_name, img)\n",
    "    \n",
    "    current_class += 1\n",
    "    \n",
    "print(\"Finish creating train and test unknown people with 1 images for class\")\n",
    "                \n",
    "# CREATE TRAIN AND TEST DATA \n",
    "for class_dir in os.listdir(LWF_FOLDER_FACE):\n",
    "    if not os.path.isdir(os.path.join(LWF_FOLDER_FACE, class_dir)):\n",
    "        continue\n",
    "\n",
    "    num_imgs = len(os.listdir(os.path.join(LWF_FOLDER_FACE, class_dir)))\n",
    "    \n",
    "    if num_imgs > 1:\n",
    "        path_test = os.path.join(LWF_CUT_FOLDER_FACE, 'test_known', class_dir)\n",
    "        os.mkdir(path_test)\n",
    "        \n",
    "        path_train = os.path.join(LWF_CUT_FOLDER_FACE, 'train', class_dir) \n",
    "        os.mkdir(path_train)\n",
    "        \n",
    "        count = 1\n",
    "        for img in image_files_in_folder(os.path.join(LWF_FOLDER_FACE, class_dir)):\n",
    "            path = img.split('/')\n",
    "            img_name = path[-1]\n",
    "            loaded_img = cv2.imread(img)\n",
    "            \n",
    "            ret, img = Cut_Img(loaded_img)\n",
    "            if ret != 0:\n",
    "                if count > num_imgs//2:\n",
    "                    os.chdir(path_train)\n",
    "                else:\n",
    "                    os.chdir(path_test)\n",
    "                cv2.imwrite(img_name, img)\n",
    "            \n",
    "            count += 1\n",
    "\n",
    "print(\"Finish creating train and test known people with more images for class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1157\n",
      "2318\n",
      "3474\n",
      "4635\n",
      "5796\n",
      "6977\n",
      "8144\n",
      "9317\n",
      "10483\n",
      "11676\n",
      "12845\n",
      "Number of images: 13233\n",
      "Number of detected images: 13186\n"
     ]
    }
   ],
   "source": [
    "# TEST FACE LOCATION\n",
    "num_imgs = 0\n",
    "num_detected_imgs = 0\n",
    "\n",
    "for class_dir in os.listdir(LWF_FOLDER_FACE):\n",
    "    if not os.path.isdir(os.path.join(LWF_FOLDER_FACE, class_dir)):\n",
    "        continue\n",
    "    \n",
    "    for img in image_files_in_folder(os.path.join(LWF_FOLDER_FACE, class_dir)):\n",
    "        num_imgs += 1\n",
    "        loaded_img = cv2.imread( img )\n",
    "        if Cut_Img(loaded_img) != 0:\n",
    "            num_detected_imgs += 1\n",
    "        \n",
    "print(\"Number of images: {}\".format(num_imgs))\n",
    "print(\"Number of detected images: {}\".format(num_detected_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "LWF_FOLDER_FACE = '/Users/khoa1799/Documents/DATA/LWF/data'\n",
    "LWF_CUT_FOLDER_FACE = '/Users/khoa1799/Documents/DATA/LWF/cut_data'\n",
    "\n",
    "LWF_PATH_USER_ID = '/Users/khoa1799/Documents/E-Healthcare-System/test_face_recognition/model/LWF_ID_Face'\n",
    "LWF_PATH_USER_IMG_ENCODED = '/Users/khoa1799/Documents/E-Healthcare-System/test_face_recognition/model/LWF_Encoded_Face'\n",
    "LWF_KNN_MODEL_PATH = \"/Users/khoa1799/Documents/E-Healthcare-System/test_face_recognition/model/LWF_knn_clf_model.clf\"\n",
    "LWF_SVM_MODEL_PATH = \"/Users/khoa1799/Documents/E-Healthcare-System/test_face_recognition/model/LWF_svm_clf_model.clf\"\n",
    "\n",
    "IMAGE_SIZE = 150\n",
    "THRESHOLD_FACE_REC = 0.6\n",
    "\n",
    "# KNN PARAs\n",
    "NUM_NEIGHBROS = 3\n",
    "KNN_ALGORITHM = 'ball_tree'\n",
    "KNN_WEIGHTS = 'distance'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD AND SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveData(known_face_IDs, known_face_encodings, path_user_id, path_user_img_encoded):\n",
    "    with open(path_user_id, mode='wb') as fp_1:\n",
    "        pickle.dump(known_face_IDs, fp_1)\n",
    "\n",
    "    with open(path_user_img_encoded, 'wb') as fp_2:\n",
    "        pickle.dump(known_face_encodings, fp_2)\n",
    "\n",
    "def SaveKNNModel(knn_clf, path_model):\n",
    "    if path_model is not None:\n",
    "        with open(path_model, 'wb') as f:\n",
    "            pickle.dump(knn_clf, f)\n",
    "\n",
    "def SaveSVMModel(svm_clf, path_model):\n",
    "    if path_model is not None:\n",
    "        with open(path_model, 'wb') as f:\n",
    "            pickle.dump(svm_clf, f)\n",
    "\n",
    "def LoadData(path_user_id, path_user_img_encoded):\n",
    "    known_face_IDs = None\n",
    "    known_face_encodings = None\n",
    "    if not os.path.exists(path_user_id):\n",
    "        print(\"There is no user id face to load\")\n",
    "        exit(-1)\n",
    "\n",
    "    with open (path_user_id, 'rb') as fp_1:\n",
    "        known_face_IDs = pickle.load(fp_1)\n",
    "\n",
    "    if not os.path.exists(path_user_img_encoded):\n",
    "        print(\"There is no user encoding face to load\")\n",
    "        exit(-1)\n",
    "\n",
    "    with open (path_user_img_encoded, 'rb') as fp_2:\n",
    "        known_face_encodings = pickle.load(fp_2)\n",
    "    \n",
    "    return known_face_IDs, known_face_encodings\n",
    "        \n",
    "def LoadKNNModel(path_model):\n",
    "    if not os.path.exists(path_model):\n",
    "        print(\"There is KNN model to load\")\n",
    "        exit(-1)\n",
    "\n",
    "    with open(path_model, 'rb') as f:\n",
    "        knn_clf = pickle.load(f)\n",
    "        return knn_clf\n",
    "\n",
    "def LoadSVMModel(path_model):\n",
    "    if not os.path.exists(SVM_MODEL_PATH):\n",
    "        print(\"There is KNN model to load\")\n",
    "        exit(-1)\n",
    "\n",
    "    with open(SVM_MODEL_PATH, 'rb') as f:\n",
    "        svm_clf = pickle.load(f)\n",
    "        return svm_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE THE USER_ID AND FACE_ENCODED FOR LWF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time load data 141.86096811294556\n"
     ]
    }
   ],
   "source": [
    "known_face_IDs = []\n",
    "known_face_encodings = []\n",
    "# Loop through each person in the training set\n",
    "time_request = time.time()\n",
    "for class_dir in os.listdir(os.path.join(LWF_CUT_FOLDER_FACE, 'train')):\n",
    "    if not os.path.isdir(os.path.join(LWF_CUT_FOLDER_FACE, 'train', class_dir)):\n",
    "        continue\n",
    "\n",
    "    for img in image_files_in_folder(os.path.join(LWF_CUT_FOLDER_FACE, 'train', class_dir)):\n",
    "        path = img.split('/')\n",
    "        user_ID = class_dir\n",
    "        img_name = path[-1]\n",
    "        loaded_img = cv2.imread( img )\n",
    "\n",
    "        # embedded_face: type ndarray (256,)\n",
    "        # embedded_face = self.__face_iden(loaded_img)\n",
    "        resized_img = cv2.resize(loaded_img, (IMAGE_SIZE,IMAGE_SIZE))\n",
    "        RGB_resized_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "        embedded_face = face_recognition.face_encodings(RGB_resized_img, [(0,IMAGE_SIZE,IMAGE_SIZE,0)])[0]\n",
    "\n",
    "        known_face_encodings.append(embedded_face)\n",
    "        known_face_IDs.append(user_ID)\n",
    "\n",
    "SaveData(known_face_IDs, known_face_encodings, LWF_PATH_USER_ID, LWF_PATH_USER_IMG_ENCODED)\n",
    "print(\"Time load data {}\".format(time.time() - time_request))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN KNN FOR LWF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing train KNN Model: 0.05706000328063965\n"
     ]
    }
   ],
   "source": [
    "knn_clf = None\n",
    "known_face_IDs = []\n",
    "known_face_encodings = []\n",
    "\n",
    "# Load data\n",
    "known_face_IDs, known_face_encodings = LoadData(LWF_PATH_USER_ID, LWF_PATH_USER_IMG_ENCODED)\n",
    "\n",
    "# Create and train the KNN classifier\n",
    "time_request = time.time()\n",
    "knn_clf = neighbors.KNeighborsClassifier(n_neighbors=NUM_NEIGHBROS, algorithm=KNN_ALGORITHM, weights=KNN_WEIGHTS)\n",
    "\n",
    "# self.__known_face_encodings is list of ndarray\n",
    "# self.__known_face_IDs is list of str\n",
    "knn_clf.fit(known_face_encodings, known_face_IDs)\n",
    "SaveKNNModel(knn_clf, LWF_KNN_MODEL_PATH)\n",
    "print(\"Finishing train KNN Model: {}\".format(time.time() - time_request))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN SVM FOR LWF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing train SVM Model: 37.93133783340454\n",
      "['George_W_Bush']\n",
      "['Aaron_Peirsol']\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "from sklearn import svm \n",
    "\n",
    "knn_clf = None\n",
    "known_face_IDs = []\n",
    "known_face_encodings = []\n",
    "\n",
    "# Load data\n",
    "known_face_IDs, known_face_encodings = LoadData()\n",
    "known_face_encodings = np.array(known_face_encodings)\n",
    "known_face_IDs = np.array(known_face_IDs)\n",
    "\n",
    "time_request = time.time()\n",
    "svm_clf = svm.SVC(kernel='rbf', gamma=0.5, C=0.1).fit(known_face_encodings, known_face_IDs)\n",
    "SaveSVMModel(svm_clf)\n",
    "print(\"Finishing train SVM Model: {}\".format(time.time() - time_request))\n",
    "# svm_clf = LoadSVMModel()\n",
    "knn_clf = LoadKNNModel()\n",
    "\n",
    "loaded_img = cv2.imread('/Users/khoa1799/Documents/E-Healthcare-System/LWF/cut_data/test_known/Aaron_Peirsol/Aaron_Peirsol_0003.jpg')\n",
    "resized_img = cv2.resize(loaded_img, (IMAGE_SIZE,IMAGE_SIZE))\n",
    "RGB_resized_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "embedded_face = face_recognition.face_encodings(RGB_resized_img, [(0,IMAGE_SIZE,IMAGE_SIZE,0)])[0]\n",
    "embedded_face = np.array(embedded_face).reshape(1,-1)\n",
    "\n",
    "print(svm_clf.predict(embedded_face))\n",
    "print(knn_clf.predict(embedded_face))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "SVM with RBF Kernel Accuracy:  76.67\n",
      "WVM with RBF Kernel F1 score:  76.36\n",
      "KNN Accuracy:  73.33\n",
      "KNN F1 score:  73.49\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]\n",
    "y = iris.target\n",
    "print(type(X_train[-1]))\n",
    "print(type(X_train))\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.80, test_size=0.20, random_state=101)\n",
    "\n",
    "rbf = svm.SVC(kernel='rbf', gamma=0.5, C=0.1).fit(X_train, y_train)\n",
    "rbf_pred = rbf.predict(X_test)\n",
    "rbf_accuracy = accuracy_score(y_test, rbf_pred)\n",
    "rbf_f1 = f1_score(y_test, rbf_pred, average='weighted')\n",
    "print('SVM with RBF Kernel Accuracy: ', \"%.2f\" % (rbf_accuracy*100))\n",
    "print('WVM with RBF Kernel F1 score: ', \"%.2f\" % (rbf_f1*100))\n",
    "\n",
    "\n",
    "knn_clf.fit(X_train, y_train)\n",
    "knn_pred = knn_clf.predict(X_test)\n",
    "knn_accuracy = accuracy_score(y_test, knn_pred)\n",
    "knn_f1 = f1_score(y_test, knn_pred, average='weighted')\n",
    "print('KNN Accuracy: ', \"%.2f\" % (knn_accuracy*100))\n",
    "print('KNN F1 score: ', \"%.2f\" % (knn_f1*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CALCULATE NUMBER OF TRAIN AND TEST IMAGES LWF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train images: 6849\n",
      "Number of test knonw images: 4296\n",
      "Number of test unknown images: 2041\n"
     ]
    }
   ],
   "source": [
    "num_train = 0\n",
    "num_test_known = 0\n",
    "num_test_unknown = 0\n",
    "for class_dir in os.listdir(os.path.join(LWF_CUT_FOLDER_FACE, 'test_known')):\n",
    "    if not os.path.isdir(os.path.join(LWF_CUT_FOLDER_FACE, 'test_known', class_dir)):\n",
    "        continue\n",
    "    num_test_known += len(os.listdir(os.path.join(LWF_CUT_FOLDER_FACE, 'test_known', class_dir)))\n",
    "\n",
    "for class_dir in os.listdir(os.path.join(LWF_CUT_FOLDER_FACE, 'test_unknown')):\n",
    "    if not os.path.isdir(os.path.join(LWF_CUT_FOLDER_FACE, 'test_unknown', class_dir)):\n",
    "        continue\n",
    "    num_test_unknown += len(os.listdir(os.path.join(LWF_CUT_FOLDER_FACE, 'test_unknown', class_dir)))\n",
    "\n",
    "for class_dir in os.listdir(os.path.join(LWF_CUT_FOLDER_FACE, 'train')):\n",
    "    if not os.path.isdir(os.path.join(LWF_CUT_FOLDER_FACE, 'train', class_dir)):\n",
    "        continue\n",
    "    num_train += len(os.listdir(os.path.join(LWF_CUT_FOLDER_FACE, 'train', class_dir)))\n",
    "    \n",
    "print(\"Number of train images: {}\".format(num_train))\n",
    "print(\"Number of test knonw images: {}\".format(num_test_known))\n",
    "print(\"Number of test unknown images: {}\".format(num_test_unknown))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST KNN FOR LWF DATASET CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy score for known faces: 0.9257448789571695\n",
      "Accurancy score for unknown faces: 0.9960803527682509\n",
      "The known image [] is missed with user [] \n",
      "The unknown image ['Rosie_Perez_0001.jpg', 'Gennifer_Flowers_0001.jpg', 'Roman_Coppola_0001.jpg', 'Jamie_King_0001.jpg', 'Giannina_Facio_0001.jpg', 'Jane_Krakowski_0001.jpg', 'Gina_Lollobrigida_0001.jpg', 'Gina_Torres_0001.jpg'] is missed with user ['Jennifer_Capriati', 'Dalia_Rabin-Pelosoff', 'Salman_Khan', 'Winona_Ryder', 'Reyyan_Uzuner', 'Sharon_Stone', 'Sophia_Loren', 'Jaqueline_Godoy'] \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# TEST FACE RECOGNITION\n",
    "knn_clf = None\n",
    "known_face_IDs = None\n",
    "known_face_encodings = None\n",
    "\n",
    "known_face = []\n",
    "unknown_face = []\n",
    "predict_known_face = []\n",
    "predict_unknown_face = []\n",
    "\n",
    "# Load KNN Model\n",
    "knn_clf = LoadKNNModel(LWF_KNN_MODEL_PATH)\n",
    "known_face_IDs, known_face_encodings = LoadData(LWF_PATH_USER_ID, LWF_PATH_USER_IMG_ENCODED)\n",
    "\n",
    "# Test known face\n",
    "for class_dir in os.listdir(os.path.join(LWF_CUT_FOLDER_FACE, 'test_known')):\n",
    "    if not os.path.isdir(os.path.join(LWF_CUT_FOLDER_FACE, 'test_known', class_dir)):\n",
    "        continue\n",
    "\n",
    "    for img in image_files_in_folder(os.path.join(LWF_CUT_FOLDER_FACE, 'test_known', class_dir)):\n",
    "        path = img.split('/')\n",
    "        user_ID = class_dir\n",
    "        img_name = path[-1]\n",
    "        loaded_img = cv2.imread(img)\n",
    "\n",
    "        known_face.append(user_ID)\n",
    "        has_face = False\n",
    "        \n",
    "        # embedded_face: type ndarray (256,)\n",
    "        # embedded_face = self.__face_iden(loaded_img)\n",
    "        resized_img = cv2.resize(loaded_img, (IMAGE_SIZE,IMAGE_SIZE))\n",
    "        RGB_resized_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "        embedded_face = face_recognition.face_encodings(RGB_resized_img, [(0,IMAGE_SIZE,IMAGE_SIZE,0)])[0]\n",
    "        embedded_face = np.array(embedded_face).reshape(1,-1)\n",
    "        \n",
    "        closet_distances = knn_clf.kneighbors(embedded_face, n_neighbors = NUM_NEIGHBROS)\n",
    "        face_id = knn_clf.predict(embedded_face)\n",
    "        meet_condition_threshold = [closet_distances[0][0][i] <= THRESHOLD_FACE_REC for i in range(len(closet_distances[0][0]))]\n",
    "\n",
    "        for i in range(len(meet_condition_threshold)):\n",
    "            if meet_condition_threshold[i] and known_face_IDs[closet_distances[1][0][i]] == face_id[-1]:\n",
    "                predict_known_face.append(face_id[-1])\n",
    "                has_face = True\n",
    "                break\n",
    "        if has_face == False:\n",
    "            predict_known_face.append('unknown')\n",
    "            \n",
    "accurancy_score = accuracy_score(known_face, predict_known_face)\n",
    "print(\"Accurancy score for known faces: {}\".format(accurancy_score))\n",
    "\n",
    "# Test unknown face\n",
    "for class_dir in os.listdir(os.path.join(LWF_CUT_FOLDER_FACE, 'test_unknown')):\n",
    "    if not os.path.isdir(os.path.join(LWF_CUT_FOLDER_FACE, 'test_unknown', class_dir)):\n",
    "        continue\n",
    "\n",
    "    for img in image_files_in_folder(os.path.join(LWF_CUT_FOLDER_FACE, 'test_unknown', class_dir)):\n",
    "        path = img.split('/')\n",
    "        user_ID = class_dir\n",
    "        img_name = path[-1]\n",
    "        loaded_img = cv2.imread(img)\n",
    "\n",
    "        unknown_face.append('unknown')\n",
    "        has_face = False\n",
    "        \n",
    "        # embedded_face: type ndarray (256,)\n",
    "        # embedded_face = self.__face_iden(loaded_img)\n",
    "        resized_img = cv2.resize(loaded_img, (IMAGE_SIZE,IMAGE_SIZE))\n",
    "        RGB_resized_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "        embedded_face = face_recognition.face_encodings(RGB_resized_img, [(0,IMAGE_SIZE,IMAGE_SIZE,0)])[0]\n",
    "        embedded_face = np.array(embedded_face).reshape(1,-1)\n",
    "        \n",
    "        closet_distances = knn_clf.kneighbors(embedded_face, n_neighbors = NUM_NEIGHBROS)\n",
    "        face_id = knn_clf.predict(embedded_face)\n",
    "        meet_condition_threshold = [closet_distances[0][0][i] <= THRESHOLD_FACE_REC for i in range(len(closet_distances[0][0]))]\n",
    "\n",
    "        for i in range(len(meet_condition_threshold)):\n",
    "            if meet_condition_threshold[i] and known_face_IDs[closet_distances[1][0][i]] == face_id[-1]:\n",
    "                predict_unknown_face.append(face_id[-1])\n",
    "                has_face = True\n",
    "                break\n",
    "        if has_face == False:\n",
    "            predict_unknown_face.append('unknown')\n",
    "                    \n",
    "accurancy_score = accuracy_score(unknown_face, predict_unknown_face)\n",
    "print(\"Accurancy score for unknown faces: {}\".format(1 - accurancy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SVM FOR CLASSIFICATION\n",
    "from sklearn.metrics import accuracy_score\n",
    "# TEST FACE RECOGNITION\n",
    "knn_clf = None\n",
    "known_face_IDs = None\n",
    "known_face_encodings = None\n",
    "\n",
    "known_face = []\n",
    "unknown_face = []\n",
    "predict_known_face = []\n",
    "predict_unknown_face = []\n",
    "\n",
    "# Load KNN Model\n",
    "knn_clf = LoadKNNModel()\n",
    "known_face_IDs, known_face_encodings = LoadData()\n",
    "\n",
    "# Test known face\n",
    "for class_dir in os.listdir(os.path.join(CUT_FOLDER_FACE, 'test_known')):\n",
    "    if not os.path.isdir(os.path.join(CUT_FOLDER_FACE, 'test_known', class_dir)):\n",
    "        continue\n",
    "\n",
    "    for img in image_files_in_folder(os.path.join(CUT_FOLDER_FACE, 'test_known', class_dir)):\n",
    "        path = img.split('/')\n",
    "        user_ID = class_dir\n",
    "        img_name = path[-1]\n",
    "        loaded_img = cv2.imread(img)\n",
    "\n",
    "        known_face.append(user_ID)\n",
    "        has_face = False\n",
    "        \n",
    "        # embedded_face: type ndarray (256,)\n",
    "        # embedded_face = self.__face_iden(loaded_img)\n",
    "        resized_img = cv2.resize(loaded_img, (IMAGE_SIZE,IMAGE_SIZE))\n",
    "        RGB_resized_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "        embedded_face = face_recognition.face_encodings(RGB_resized_img, [(0,IMAGE_SIZE,IMAGE_SIZE,0)])[0]\n",
    "        embedded_face = np.array(embedded_face).reshape(1,-1)\n",
    "        \n",
    "        closet_distances = knn_clf.kneighbors(embedded_face, n_neighbors = NUM_NEIGHBROS)\n",
    "        face_id = knn_clf.predict(embedded_face)\n",
    "        meet_condition_threshold = [closet_distances[0][0][i] <= THRESHOLD_FACE_REC for i in range(len(closet_distances[0][0]))]\n",
    "\n",
    "        for i in range(len(meet_condition_threshold)):\n",
    "            if meet_condition_threshold[i] and known_face_IDs[closet_distances[1][0][i]] == face_id[-1]:\n",
    "                predict_known_face.append(face_id[-1])\n",
    "                has_face = True\n",
    "                break\n",
    "        if has_face == False:\n",
    "            predict_known_face.append('unknown')\n",
    "            \n",
    "accurancy_score = accuracy_score(known_face, predict_known_face)\n",
    "print(\"Accurancy score for known faces: {}\".format(accurancy_score))\n",
    "\n",
    "# Test unknown face\n",
    "for class_dir in os.listdir(os.path.join(CUT_FOLDER_FACE, 'test_unknown')):\n",
    "    if not os.path.isdir(os.path.join(CUT_FOLDER_FACE, 'test_unknown', class_dir)):\n",
    "        continue\n",
    "\n",
    "    for img in image_files_in_folder(os.path.join(CUT_FOLDER_FACE, 'test_unknown', class_dir)):\n",
    "        path = img.split('/')\n",
    "        user_ID = class_dir\n",
    "        img_name = path[-1]\n",
    "        loaded_img = cv2.imread(img)\n",
    "\n",
    "        unknown_face.append('unknown')\n",
    "        has_face = False\n",
    "        \n",
    "        # embedded_face: type ndarray (256,)\n",
    "        # embedded_face = self.__face_iden(loaded_img)\n",
    "        resized_img = cv2.resize(loaded_img, (IMAGE_SIZE,IMAGE_SIZE))\n",
    "        RGB_resized_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "        embedded_face = face_recognition.face_encodings(RGB_resized_img, [(0,IMAGE_SIZE,IMAGE_SIZE,0)])[0]\n",
    "        embedded_face = np.array(embedded_face).reshape(1,-1)\n",
    "        \n",
    "        closet_distances = knn_clf.kneighbors(embedded_face, n_neighbors = NUM_NEIGHBROS)\n",
    "        face_id = knn_clf.predict(embedded_face)\n",
    "        meet_condition_threshold = [closet_distances[0][0][i] <= THRESHOLD_FACE_REC for i in range(len(closet_distances[0][0]))]\n",
    "\n",
    "        for i in range(len(meet_condition_threshold)):\n",
    "            if meet_condition_threshold[i] and known_face_IDs[closet_distances[1][0][i]] == face_id[-1]:\n",
    "                predict_unknown_face.append(face_id[-1])\n",
    "                has_face = True\n",
    "                break\n",
    "        if has_face == False:\n",
    "            predict_unknown_face.append('unknown')\n",
    "                    \n",
    "accurancy_score = accuracy_score(unknown_face, predict_unknown_face)\n",
    "print(\"Accurancy score for unknown faces: {}\".format(1 - accurancy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VN dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PATH FOR VN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "VN_FOLDER_FACE = '/Users/khoa1799/Documents/E-Healthcare-System/LWF/VN_data'\n",
    "VN_CUT_FOLDER_FACE = '/Users/khoa1799/Documents/E-Healthcare-System/LWF/VN_cut_data'\n",
    "\n",
    "VN_PATH_USER_ID = '/Users/khoa1799/Documents/E-Healthcare-System/LWF/model/VN_ID_Face'\n",
    "VN_PATH_USER_IMG_ENCODED = '/Users/khoa1799/Documents/E-Healthcare-System/LWF/model/VN_Encoded_Face'\n",
    "VN_KNN_MODEL_PATH = \"/Users/khoa1799/Documents/E-Healthcare-System/LWF/model/VN_knn_clf_model.clf\"\n",
    "VN_SVM_MODEL_PATH = \"/Users/khoa1799/Documents/E-Healthcare-System/LWF/model/VN_svm_clf_model.clf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_dir in os.listdir(VN_FOLDER_FACE):\n",
    "    if not os.path.isdir(VN_FOLDER_FACE):\n",
    "        continue\n",
    "        \n",
    "    path = os.path.join(VN_FOLDER_FACE, class_dir)\n",
    "    num_imgs = len(os.listdir(path))\n",
    "    if num_imgs < 6:\n",
    "        shutil.rmtree(path)\n",
    "        \n",
    "#         count = num_imgs - 5\n",
    "#         for img in image_files_in_folder(os.path.join(path, class_dir)):\n",
    "#             os.remove(img)\n",
    "#             count -= 1\n",
    "#             if count ==0:\n",
    "#                 break\n",
    "# for class_dir in os.listdir(VN_FOLDER_FACE):\n",
    "#     if not os.path.isdir(VN_FOLDER_FACE):\n",
    "#         continue\n",
    "    \n",
    "#     num_imgs = len(os.listdir(os.path.join(VN_FOLDER_FACE, class_dir)))\n",
    "#     if num_imgs <2:\n",
    "#         print(class_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DELETE DATA FOLDERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(VN_CUT_FOLDER_FACE + '/test')\n",
    "shutil.rmtree(VN_CUT_FOLDER_FACE + '/train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE VN DATA FOLDERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = os.path.join(VN_CUT_FOLDER_FACE, 'test')\n",
    "os.mkdir(path_test)\n",
    "\n",
    "path_train = os.path.join(VN_CUT_FOLDER_FACE, 'train') \n",
    "os.mkdir(path_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE TRAIN AND TEST DATA VN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 936\n"
     ]
    }
   ],
   "source": [
    "num_class_has_more_img = 0\n",
    "num_classes = 0\n",
    "user_ID = \"\"\n",
    "img_name = \"\"\n",
    "\n",
    "num_classes = len(os.listdir(os.path.join(VN_FOLDER_FACE)))\n",
    "current_class = 1\n",
    "print(\"Number of classes: {}\".format(num_classes))\n",
    "                \n",
    "# CREATE TRAIN AND TEST DATA \n",
    "for class_dir in os.listdir(VN_FOLDER_FACE):\n",
    "    if not os.path.isdir(os.path.join(VN_FOLDER_FACE, class_dir)):\n",
    "        continue\n",
    "\n",
    "    num_imgs = len(os.listdir(os.path.join(VN_FOLDER_FACE, class_dir)))\n",
    "    \n",
    "    path_test = os.path.join(VN_CUT_FOLDER_FACE, 'test', class_dir)\n",
    "    os.mkdir(path_test)\n",
    "    \n",
    "    path_train = os.path.join(VN_CUT_FOLDER_FACE, 'train', class_dir) \n",
    "    os.mkdir(path_train)\n",
    "\n",
    "    count = 1\n",
    "    for img in image_files_in_folder(os.path.join(VN_FOLDER_FACE, class_dir)):\n",
    "        path = img.split('/')\n",
    "        img_name = path[-1]\n",
    "        loaded_img = cv2.imread(img)\n",
    "\n",
    "        ret, img = Cut_Img(loaded_img)\n",
    "        if ret != 0:\n",
    "            if count > 5:\n",
    "                os.chdir(path_test)\n",
    "            else:\n",
    "                os.chdir(path_train)\n",
    "            cv2.imwrite(img_name, img)\n",
    "\n",
    "        count += 1\n",
    "\n",
    "print(\"Finish creating train and test known people with more images for class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE THE face_id and face_encoded for VN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time load data 50.403992891311646\n"
     ]
    }
   ],
   "source": [
    "known_face_IDs = []\n",
    "known_face_encodings = []\n",
    "# Loop through each person in the training set\n",
    "time_request = time.time()\n",
    "for class_dir in os.listdir(os.path.join(VN_CUT_FOLDER_FACE, 'train')):\n",
    "    if not os.path.isdir(os.path.join(VN_CUT_FOLDER_FACE, 'train', class_dir)):\n",
    "        continue\n",
    "\n",
    "    for img in image_files_in_folder(os.path.join(VN_CUT_FOLDER_FACE, 'train', class_dir)):\n",
    "        path = img.split('/')\n",
    "        user_ID = class_dir\n",
    "        img_name = path[-1]\n",
    "        loaded_img = cv2.imread( img )\n",
    "\n",
    "        # embedded_face: type ndarray (256,)\n",
    "        # embedded_face = self.__face_iden(loaded_img)\n",
    "        resized_img = cv2.resize(loaded_img, (IMAGE_SIZE,IMAGE_SIZE))\n",
    "        RGB_resized_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "        embedded_face = face_recognition.face_encodings(RGB_resized_img, [(0,IMAGE_SIZE,IMAGE_SIZE,0)])[0]\n",
    "\n",
    "        known_face_encodings.append(embedded_face)\n",
    "        known_face_IDs.append(user_ID)\n",
    "\n",
    "SaveData(known_face_encodings, known_face_IDs, VN_PATH_USER_IMG_ENCODED, VN_PATH_USER_ID)\n",
    "print(\"Time load data {}\".format(time.time() - time_request))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN KNN for VN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing train KNN Model: 0.0171511173248291\n"
     ]
    }
   ],
   "source": [
    "knn_clf = None\n",
    "known_face_IDs = []\n",
    "known_face_encodings = []\n",
    "\n",
    "# Load data\n",
    "known_face_IDs, known_face_encodings = LoadData(VN_PATH_USER_ID, VN_PATH_USER_IMG_ENCODED)\n",
    "\n",
    "# Create and train the KNN classifier\n",
    "time_request = time.time()\n",
    "knn_clf = neighbors.KNeighborsClassifier(n_neighbors=NUM_NEIGHBROS, algorithm=KNN_ALGORITHM, weights=KNN_WEIGHTS)\n",
    "\n",
    "# self.__known_face_encodings is list of ndarray\n",
    "# self.__known_face_IDs is list of str\n",
    "knn_clf.fit(known_face_encodings, known_face_IDs)\n",
    "SaveKNNModel(knn_clf, VN_KNN_MODEL_PATH)\n",
    "print(\"Finishing train KNN Model: {}\".format(time.time() - time_request))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST KNN FOR CLASSIFICATION VN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy score for known faces: 0.5913555992141454\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# TEST FACE RECOGNITION\n",
    "knn_clf = None\n",
    "known_face_IDs = None\n",
    "known_face_encodings = None\n",
    "\n",
    "known_face = []\n",
    "unknown_face = []\n",
    "predict_known_face = []\n",
    "predict_unknown_face = []\n",
    "\n",
    "# Load KNN Model\n",
    "knn_clf = LoadKNNModel(VN_KNN_MODEL_PATH)\n",
    "known_face_IDs, known_face_encodings = LoadData(VN_PATH_USER_ID, VN_PATH_USER_IMG_ENCODED)\n",
    "\n",
    "# Test known face\n",
    "for class_dir in os.listdir(os.path.join(VN_CUT_FOLDER_FACE, 'test')):\n",
    "    if not os.path.isdir(os.path.join(VN_CUT_FOLDER_FACE, 'test', class_dir)):\n",
    "        continue\n",
    "\n",
    "    for img in image_files_in_folder(os.path.join(VN_CUT_FOLDER_FACE, 'test', class_dir)):\n",
    "        path = img.split('/')\n",
    "        user_ID = class_dir\n",
    "        img_name = path[-1]\n",
    "        loaded_img = cv2.imread(img)\n",
    "\n",
    "        known_face.append(user_ID)\n",
    "        has_face = False\n",
    "        \n",
    "        # embedded_face: type ndarray (256,)\n",
    "        # embedded_face = self.__face_iden(loaded_img)\n",
    "        resized_img = cv2.resize(loaded_img, (IMAGE_SIZE,IMAGE_SIZE))\n",
    "        RGB_resized_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "        embedded_face = face_recognition.face_encodings(RGB_resized_img, [(0,IMAGE_SIZE,IMAGE_SIZE,0)])[0]\n",
    "        embedded_face = np.array(embedded_face).reshape(1,-1)\n",
    "        \n",
    "        closet_distances = knn_clf.kneighbors(embedded_face, n_neighbors = NUM_NEIGHBROS)\n",
    "        face_id = knn_clf.predict(embedded_face)\n",
    "        meet_condition_threshold = [closet_distances[0][0][i] <= THRESHOLD_FACE_REC for i in range(len(closet_distances[0][0]))]\n",
    "\n",
    "        for i in range(len(meet_condition_threshold)):\n",
    "            if meet_condition_threshold[i] and known_face_IDs[closet_distances[1][0][i]] == face_id[-1]:\n",
    "                predict_known_face.append(face_id[-1])\n",
    "                has_face = True\n",
    "                break\n",
    "        if has_face == False:\n",
    "            predict_known_face.append('unknown')\n",
    "            \n",
    "accurancy_score = accuracy_score(known_face, predict_known_face)\n",
    "print(\"Accurancy score for known faces: {}\".format(accurancy_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
